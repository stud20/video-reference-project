# web/components/analyze/reanalysis.py
"""
ì¬ì¶”ë¡  ê¸°ëŠ¥ - ë©€í‹° ëª¨ë¸ ì§€ì›
"""

import streamlit as st
import os
import json
from typing import Dict, Any, Optional, List
from datetime import datetime
from dataclasses import dataclass

from utils.logger import get_logger
from core.analysis import VideoAnalyzer
from core.analysis.providers import OpenAIProvider, ClaudeProvider, GeminiProvider
from core.video.models import Video

logger = get_logger(__name__)


@dataclass
class ModelComparisonResult:
    """ëª¨ë¸ ë¹„êµ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    model_name: str
    display_name: str
    result: Optional[Dict[str, Any]]
    status: str  # 'success', 'failed', 'running'
    error_message: Optional[str] = None
    analysis_time: Optional[float] = None


class MultiModelAnalyzer:
    """ë©€í‹° ëª¨ë¸ ë¶„ì„ê¸°"""
    
    # ì§€ì› ëª¨ë¸ ì •ì˜
    SUPPORTED_MODELS = {
        "gpt-4o": {
            "display_name": "GPT-4o",
            "description": "OpenAIì˜ ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ (ê· í˜•ì¡íŒ ë¶„ì„)",
            "color": "#10A37F",
            "icon": "ğŸ¤–",
            "provider_class": OpenAIProvider,
            "config": {
                "model": "gpt-4o",
                "api_key": os.getenv("FACTCHAT_API_KEY", "NPpDGrF4ShhrecUsBJm1dIIW7DZab4qC"),
                "api_type": "factchat"
            }
        },
        "claude-sonnet-4-20250514": {
            "display_name": "Claude Sonnet 4",
            "description": "Anthropicì˜ Claude Sonnet (ìƒì„¸í•œ ë¶„ì„)",
            "color": "#D97706",
            "icon": "ğŸ§ ",
            "provider_class": ClaudeProvider,
            "config": {
                "model": "claude-sonnet-4-20250514",
                "api_key": os.getenv("FACTCHAT_API_KEY", "NPpDGrF4ShhrecUsBJm1dIIW7DZab4qC"),
                "api_type": "factchat"
            }
        },
        "gemini-2.0-flash": {
            "display_name": "Gemini 2.0 Flash",
            "description": "Googleì˜ Gemini Flash (ì°½ì˜ì  ë¶„ì„)",
            "color": "#4285F4",
            "icon": "âœ¨",
            "provider_class": GeminiProvider,
            "config": {
                "model": "gemini-2.0-flash",
                "api_key": os.getenv("FACTCHAT_API_KEY", "NPpDGrF4ShhrecUsBJm1dIIW7DZab4qC"),
                "api_type": "factchat"
            }
        }
    }
    
    def __init__(self):
        self.logger = get_logger(__name__)
    
    def get_model_info(self, model_name: str) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return self.SUPPORTED_MODELS.get(model_name, {})
    
    def analyze_with_single_model(self, video: Video, model_name: str) -> ModelComparisonResult:
        """ë‹¨ì¼ ëª¨ë¸ë¡œ ì¬ë¶„ì„"""
        start_time = datetime.now()
        model_info = self.get_model_info(model_name)
        
        result = ModelComparisonResult(
            model_name=model_name,
            display_name=model_info["display_name"],
            result=None,
            status="running"
        )
        
        try:
            self.logger.info(f"ğŸ¤– {model_info['display_name']} ë¶„ì„ ì‹œì‘...")
            
            # Provider ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            provider_class = model_info["provider_class"]
            provider = provider_class(**model_info["config"])
            
            # VideoAnalyzer ìƒì„± ë° ë¶„ì„ ì‹¤í–‰
            analyzer = VideoAnalyzer(provider=provider)
            analysis_result = analyzer.analyze_video(video)
            
            if analysis_result:
                result.result = analysis_result
                result.status = "success"
                self.logger.info(f"âœ… {model_info['display_name']} ë¶„ì„ ì™„ë£Œ")
            else:
                result.status = "failed"
                result.error_message = "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
                self.logger.error(f"âŒ {model_info['display_name']} ë¶„ì„ ì‹¤íŒ¨: ê²°ê³¼ ì—†ìŒ")
        
        except Exception as e:
            result.status = "failed"
            result.error_message = str(e)
            self.logger.error(f"âŒ {model_info['display_name']} ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ë¶„ì„ ì‹œê°„ ê³„ì‚°
        end_time = datetime.now()
        result.analysis_time = (end_time - start_time).total_seconds()
        
        return result
    
    def analyze_with_multiple_models(self, video: Video, model_names: List[str]) -> Dict[str, ModelComparisonResult]:
        """ì—¬ëŸ¬ ëª¨ë¸ë¡œ ë¶„ì„"""
        self.logger.info(f"ğŸ”¬ {len(model_names)}ê°œ ëª¨ë¸ë¡œ ë¶„ì„ ì‹œì‘...")
        
        results = {}
        
        # ìˆœì°¨ ì‹¤í–‰ (Streamlit í™˜ê²½ì—ì„œ ì•ˆì „)
        for model_name in model_names:
            result = self.analyze_with_single_model(video, model_name)
            results[model_name] = result
        
        self.logger.info(f"âœ… ëª¨ë“  ëª¨ë¸ ë¶„ì„ ì™„ë£Œ")
        return results
    
    def save_comparison_result(self, video: Video, comparison_results: Dict[str, ModelComparisonResult], 
                             selected_model: Optional[str] = None):
        """ë¹„êµ ê²°ê³¼ ì €ì¥"""
        try:
            # ë¹„êµ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
            comparison_dir = os.path.join(video.session_dir, "model_comparison")
            os.makedirs(comparison_dir, exist_ok=True)
            
            # ë¹„êµ ê²°ê³¼ ì €ì¥
            comparison_data = {
                "timestamp": datetime.now().isoformat(),
                "models_analyzed": list(comparison_results.keys()),
                "selected_model": selected_model,
                "results": {}
            }
            
            for model_name, comp_result in comparison_results.items():
                comparison_data["results"][model_name] = {
                    "display_name": comp_result.display_name,
                    "status": comp_result.status,
                    "error_message": comp_result.error_message,
                    "analysis_time": comp_result.analysis_time,
                    "result": comp_result.result if comp_result.result else None
                }
            
            # JSONìœ¼ë¡œ ì €ì¥
            comparison_file = os.path.join(comparison_dir, 
                                         f"comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            with open(comparison_file, 'w', encoding='utf-8') as f:
                json.dump(comparison_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ğŸ’¾ ë¹„êµ ê²°ê³¼ ì €ì¥: {comparison_file}")
            
            # ì„ íƒëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë©”ì¸ ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸
            if selected_model and selected_model in comparison_results:
                selected_result = comparison_results[selected_model].result
                if selected_result:
                    self._update_main_analysis_result(video, selected_result, selected_model)
            
        except Exception as e:
            self.logger.error(f"ë¹„êµ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _update_main_analysis_result(self, video: Video, result: Dict[str, Any], model_name: str):
        """ë©”ì¸ ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        try:
            # ì‚¬ìš©ìê°€ ì„ íƒí–ˆìŒì„ í‘œì‹œ
            result['user_selected'] = True
            result['selected_from_comparison'] = True
            result['model_used'] = f"factchat:{model_name}"
            
            # Video ê°ì²´ì— ê²°ê³¼ ì €ì¥
            video.analysis_result = result
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            result_path = os.path.join(video.session_dir, "analysis_result.json")
            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"âœ… ë©”ì¸ ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸: {model_name}")
            
        except Exception as e:
            self.logger.error(f"ë©”ì¸ ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
multi_model_analyzer = MultiModelAnalyzer()


def render_reanalysis_section(video: Video):
    """ì¬ì¶”ë¡  ì„¹ì…˜ ë Œë”ë§"""
    if not video:
        st.error("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown("### ğŸ”„ AI ëª¨ë¸ ì¬ì¶”ë¡ ")
    st.markdown("ë‹¤ë¥¸ AI ëª¨ë¸ë¡œ ì¬ë¶„ì„í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”.")
    
    # ì¬ì¶”ë¡  ì˜µì…˜ ì„ íƒ
    with st.expander("ğŸ¯ ì¬ì¶”ë¡  ì˜µì…˜", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            # ëª¨ë¸ ì„ íƒ
            available_models = list(multi_model_analyzer.SUPPORTED_MODELS.keys())
            selected_models = st.multiselect(
                "ë¶„ì„í•  ëª¨ë¸ ì„ íƒ",
                options=available_models,
                default=available_models[:2],  # ê¸°ë³¸ì ìœ¼ë¡œ ì²˜ìŒ 2ê°œ ì„ íƒ
                help="ì—¬ëŸ¬ ëª¨ë¸ì„ ì„ íƒí•˜ì—¬ ê²°ê³¼ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
        with col2:
            # ë¶„ì„ ëª¨ë“œ
            analysis_mode = st.radio(
                "ë¶„ì„ ëª¨ë“œ",
                options=["ë¹ ë¥¸ ë¶„ì„", "ìƒì„¸ ë¶„ì„"],
                index=0,
                help="ìƒì„¸ ë¶„ì„ì€ ë” ë§ì€ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
            )
    
    # ëª¨ë¸ ì •ë³´ í‘œì‹œ
    if selected_models:
        st.markdown("#### ì„ íƒëœ ëª¨ë¸")
        cols = st.columns(len(selected_models))
        
        for idx, model_name in enumerate(selected_models):
            model_info = multi_model_analyzer.get_model_info(model_name)
            with cols[idx]:
                st.markdown(f"""
                <div style="text-align: center; padding: 10px; border-radius: 10px; 
                           background-color: {model_info['color']}20; border: 1px solid {model_info['color']};">
                    <h4>{model_info['icon']} {model_info['display_name']}</h4>
                    <p style="font-size: 0.9em; color: gray;">{model_info['description']}</p>
                </div>
                """, unsafe_allow_html=True)
    
    # ì¬ë¶„ì„ ë²„íŠ¼
    if st.button("ğŸ”„ ì¬ë¶„ì„ ì‹œì‘", use_container_width=True, type="primary", 
                disabled=not selected_models):
        if not selected_models:
            st.warning("âš ï¸ ë¶„ì„í•  ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # ë¶„ì„ ì§„í–‰
        with st.spinner(f"ğŸ”„ {len(selected_models)}ê°œ ëª¨ë¸ë¡œ ì¬ë¶„ì„ ì¤‘..."):
            # ì§„í–‰ ìƒí™© í‘œì‹œìš© placeholder
            progress_container = st.container()
            
            # ê° ëª¨ë¸ë³„ë¡œ ë¶„ì„ ì‹¤í–‰
            comparison_results = {}
            
            for idx, model_name in enumerate(selected_models):
                model_info = multi_model_analyzer.get_model_info(model_name)
                
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                with progress_container:
                    progress = (idx + 1) / len(selected_models)
                    st.progress(progress, text=f"{model_info['icon']} {model_info['display_name']} ë¶„ì„ ì¤‘...")
                
                # ëª¨ë¸ ë¶„ì„ ì‹¤í–‰
                result = multi_model_analyzer.analyze_with_single_model(video, model_name)
                comparison_results[model_name] = result
        
        # ê²°ê³¼ í‘œì‹œ
        st.success(f"âœ… {len(selected_models)}ê°œ ëª¨ë¸ ë¶„ì„ ì™„ë£Œ!")
        
        # ê²°ê³¼ ë¹„êµ í‘œì‹œ
        _display_comparison_results(video, comparison_results)


def _display_comparison_results(video: Video, comparison_results: Dict[str, ModelComparisonResult]):
    """ë¹„êµ ê²°ê³¼ í‘œì‹œ"""
    st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¹„êµ")
    
    # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
    successful_results = {k: v for k, v in comparison_results.items() if v.status == "success"}
    
    if not successful_results:
        st.error("âŒ ëª¨ë“  ëª¨ë¸ ë¶„ì„ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # íƒ­ìœ¼ë¡œ ê° ëª¨ë¸ ê²°ê³¼ í‘œì‹œ
    tabs = st.tabs([
        f"{multi_model_analyzer.get_model_info(model)['icon']} {result.display_name}" 
        for model, result in successful_results.items()
    ])
    
    for idx, (model_name, result) in enumerate(successful_results.items()):
        with tabs[idx]:
            if result.result:
                _display_single_result(model_name, result)
    
    # ê²°ê³¼ ì„ íƒ ë° ì €ì¥
    st.markdown("---")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        selected_model = st.selectbox(
            "ğŸ“Œ ë©”ì¸ ê²°ê³¼ë¡œ ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ",
            options=list(successful_results.keys()),
            format_func=lambda x: f"{multi_model_analyzer.get_model_info(x)['icon']} {successful_results[x].display_name}"
        )
    
    with col2:
        if st.button("ğŸ’¾ ì„ íƒëœ ê²°ê³¼ ì €ì¥", use_container_width=True):
            multi_model_analyzer.save_comparison_result(video, comparison_results, selected_model)
            st.success("âœ… ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    with col3:
        if st.button("ğŸ“Š ë¹„êµ ê²°ê³¼ ì €ì¥", use_container_width=True):
            multi_model_analyzer.save_comparison_result(video, comparison_results)
            st.success("âœ… ë¹„êµ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")


def _display_single_result(model_name: str, result: ModelComparisonResult):
    """ë‹¨ì¼ ëª¨ë¸ ê²°ê³¼ í‘œì‹œ"""
    model_info = multi_model_analyzer.get_model_info(model_name)
    
    # ë¶„ì„ ì‹œê°„ í‘œì‹œ
    if result.analysis_time:
        st.info(f"â±ï¸ ë¶„ì„ ì‹œê°„: {result.analysis_time:.1f}ì´ˆ")
    
    if result.status == "failed":
        st.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.error_message}")
        return
    
    if not result.result:
        st.warning("âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²°ê³¼ í‘œì‹œ
    res = result.result
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ¬ ì¥ë¥´")
        st.info(res.get('genre', 'Unknown'))
        
        st.markdown("#### ğŸ¨ í‘œí˜„ í˜•ì‹")
        st.info(res.get('expression_style', 'ì‹¤ì‚¬'))
    
    with col2:
        st.markdown("#### ğŸ¯ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤")
        st.info(res.get('target_audience', 'ì¼ë°˜'))
        
        st.markdown("#### ğŸŒˆ ë¬´ë“œ/í†¤")
        st.info(res.get('mood_tone', 'ì¤‘ë¦½ì '))
    
    # ì¶”ë¡  ê·¼ê±°
    st.markdown("#### ğŸ’­ ë¶„ì„ ê·¼ê±°")
    st.text_area("", value=res.get('reasoning', ''), height=150, disabled=True)
    
    # ì£¼ìš” íŠ¹ì§•
    st.markdown("#### âœ¨ ì£¼ìš” íŠ¹ì§•")
    st.text_area("", value=res.get('features', ''), height=100, disabled=True)
    
    # íƒœê·¸
    if res.get('tags'):
        st.markdown("#### ğŸ·ï¸ íƒœê·¸")
        tag_html = " ".join([f"<span style='background-color: {model_info['color']}30; "
                            f"padding: 5px 10px; margin: 2px; border-radius: 15px; "
                            f"display: inline-block;'>#{tag}</span>" 
                            for tag in res['tags']])
        st.markdown(tag_html, unsafe_allow_html=True)
