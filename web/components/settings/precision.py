# web/components/settings/precision.py
"""
ë¶„ì„ ì •ë°€ë„ ì„¤ì • ëª¨ë“ˆ - .env íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸ ì§€ì›
"""

import streamlit as st
import os
from utils.constants import PRECISION_DESCRIPTIONS, TIME_ESTIMATES
from utils.env_manager import EnvManager
from utils.logger import get_logger

logger = get_logger(__name__)


def render_precision_settings():
    """ë¶„ì„ ì •ë°€ë„ ì„¤ì • ë Œë”ë§"""
    st.subheader("ğŸ¯ ë¶„ì„ ì •ë°€ë„ ì„¤ì •")
    
    # í˜„ì¬ ì •ë°€ë„ ë ˆë²¨
    current_precision = EnvManager.get_int("SCENE_PRECISION_LEVEL", 5)
    
    # ë©”ì¸ ì •ë°€ë„ ì„¤ì •
    col1, col2 = st.columns([3, 1])
    
    with col1:
        new_precision = st.slider(
            "ì •ë°€ë„ ë ˆë²¨",
            min_value=1,
            max_value=10,
            value=current_precision,
            help="ì”¬ ê·¸ë£¹í™”ì˜ ì •ë°€ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤"
        )
    
    with col2:
        st.metric("í˜„ì¬ ë ˆë²¨", f"{current_precision}")
        if new_precision != current_precision:
            st.caption(f"â†’ {new_precision}")
    
    # ë ˆë²¨ ë³€ê²½ ì‹œ ì¦‰ì‹œ í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸
    if new_precision != current_precision:
        # í™˜ê²½ë³€ìˆ˜ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
        os.environ["SCENE_PRECISION_LEVEL"] = str(new_precision)
        
        # .env íŒŒì¼ì—ë„ ì €ì¥
        if EnvManager.update("SCENE_PRECISION_LEVEL", new_precision):
            st.success(f"âœ… ì •ë°€ë„ ë ˆë²¨ì´ {current_precision}ì—ì„œ {new_precision}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # ì„¸ì…˜ ìƒíƒœì—ë„ ì €ì¥ (ì˜µì…˜)
            st.session_state['scene_precision_level'] = new_precision
    
    # ì •ë°€ë„ ë ˆë²¨ ìƒì„¸ ì •ë³´
    st.markdown("---")
    render_precision_details(new_precision)
    
    # ê³ ê¸‰ ì„¤ì •
    st.markdown("---")
    render_advanced_settings()
    
    # ì •ë°€ë„ ë ˆë²¨ë³„ ë¹„êµí‘œ
    st.markdown("---")
    render_precision_comparison()


def render_advanced_settings():
    """ê³ ê¸‰ ì”¬ ì¶”ì¶œ ì„¤ì •"""
    with st.expander("âš™ï¸ ê³ ê¸‰ ì”¬ ì¶”ì¶œ ì„¤ì •"):
        st.markdown("### ì”¬ ê°ì§€ ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            current_threshold = EnvManager.get_float("SCENE_THRESHOLD", 0.3)
            scene_threshold = st.slider(
                "ì”¬ ì „í™˜ ê°ì§€ ì„ê³„ê°’",
                min_value=0.1,
                max_value=0.8,
                value=current_threshold,
                step=0.05,
                help="ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ì”¬ ì „í™˜ì„ ê°ì§€í•©ë‹ˆë‹¤"
            )
            if scene_threshold != current_threshold:
                EnvManager.update("SCENE_THRESHOLD", scene_threshold)
            
            current_duration = EnvManager.get_float("MIN_SCENE_DURATION", 0.5)
            min_scene_duration = st.number_input(
                "ìµœì†Œ ì”¬ ì§€ì†ì‹œê°„ (ì´ˆ)",
                min_value=0.1,
                max_value=5.0,
                value=current_duration,
                step=0.1,
                help="ì´ë³´ë‹¤ ì§§ì€ ì”¬ì€ ë¬´ì‹œë©ë‹ˆë‹¤"
            )
            if min_scene_duration != current_duration:
                EnvManager.update("MIN_SCENE_DURATION", min_scene_duration)
        
        with col2:
            current_similarity = EnvManager.get_float("SCENE_SIMILARITY_THRESHOLD", 0.92)
            similarity_threshold = st.slider(
                "ì”¬ ìœ ì‚¬ë„ ì„ê³„ê°’",
                min_value=0.80,
                max_value=0.99,
                value=current_similarity,
                step=0.01,
                help="ë†’ì„ìˆ˜ë¡ ë” ìœ ì‚¬í•œ ì”¬ë“¤ë§Œ ê·¸ë£¹í™”ë©ë‹ˆë‹¤"
            )
            if similarity_threshold != current_similarity:
                EnvManager.update("SCENE_SIMILARITY_THRESHOLD", similarity_threshold)
            
            current_max_images = EnvManager.get_int("MAX_ANALYSIS_IMAGES", 10)
            max_analysis_images = st.number_input(
                "ìµœëŒ€ ë¶„ì„ ì´ë¯¸ì§€ ìˆ˜",
                min_value=5,
                max_value=20,
                value=current_max_images,
                help="AI ë¶„ì„ì— ì‚¬ìš©í•  ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜"
            )
            if max_analysis_images != current_max_images:
                EnvManager.update("MAX_ANALYSIS_IMAGES", max_analysis_images)
        
        st.markdown("### ê·¸ë£¹í™” ì„¤ì •")
        
        col3, col4 = st.columns(2)
        
        with col3:
            current_min_scenes = EnvManager.get_int("MIN_SCENES_FOR_GROUPING", 10)
            min_scenes_for_grouping = st.number_input(
                "ê·¸ë£¹í™” ìµœì†Œ ì”¬ ê°œìˆ˜",
                min_value=5,
                max_value=30,
                value=current_min_scenes,
                help="ì´ë³´ë‹¤ ì ì€ ì”¬ì€ ê·¸ë£¹í™”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
            )
            if min_scenes_for_grouping != current_min_scenes:
                EnvManager.update("MIN_SCENES_FOR_GROUPING", min_scenes_for_grouping)
        
        with col4:
            current_hash = EnvManager.get_int("SCENE_HASH_THRESHOLD", 5)
            hash_threshold = st.number_input(
                "í•´ì‹œ ì°¨ì´ ì„ê³„ê°’",
                min_value=1,
                max_value=20,
                value=current_hash,
                help="ì§€ê°ì  í•´ì‹œì˜ ì°¨ì´ í—ˆìš©ì¹˜"
            )
            if hash_threshold != current_hash:
                EnvManager.update("SCENE_HASH_THRESHOLD", hash_threshold)
        
        # ë³€ê²½ì‚¬í•­ ì €ì¥ ì•Œë¦¼
        if st.button("ğŸ’¾ ëª¨ë“  ë³€ê²½ì‚¬í•­ì´ ìë™ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤", disabled=True):
            pass


def render_precision_details(level: int):
    """ì •ë°€ë„ ë ˆë²¨ ìƒì„¸ ì •ë³´ í‘œì‹œ"""
    st.markdown("### ğŸ“Š ë ˆë²¨ ìƒì„¸ ì •ë³´")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info(f"""
        **{PRECISION_DESCRIPTIONS[level]}**
        
        ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: **{TIME_ESTIMATES[level]}**
        """)
    
    with col2:
        # ëª©í‘œ ì”¬ ê°œìˆ˜ ê³„ì‚°
        target_scenes = get_target_scene_count(level)
        st.metric("ëª©í‘œ ì”¬ ê°œìˆ˜", f"{target_scenes}ê°œ")
        
        # í™œì„±í™”ëœ íŠ¹ì§• ìˆ˜
        active_features = get_active_features_count(level)
        st.metric("í™œì„± íŠ¹ì§•", f"{active_features}ê°œ")
    
    with col3:
        # ì²˜ë¦¬ ì†ë„ì™€ ì •í™•ë„ ê²Œì´ì§€
        speed = 11 - level  # 1-10 ë°˜ì „
        accuracy = level
        
        st.markdown("**ì²˜ë¦¬ ì†ë„**")
        st.progress(speed / 10)
        st.markdown("**ë¶„ì„ ì •í™•ë„**")
        st.progress(accuracy / 10)
    
    # í™œì„±í™”ëœ íŠ¹ì§• ëª©ë¡
    with st.expander("ğŸ” í™œì„±í™”ëœ íŠ¹ì§• ë³´ê¸°"):
        features = get_active_features_list(level)
        for feature in features:
            st.write(f"â€¢ {feature}")


def render_precision_comparison():
    """ì •ë°€ë„ ë ˆë²¨ë³„ ë¹„êµí‘œ"""
    st.markdown("### ğŸ“ˆ ì •ë°€ë„ ë ˆë²¨ ë¹„êµ")
    
    # ë¹„êµ ë°ì´í„° ì¤€ë¹„
    comparison_data = []
    for level in range(1, 11):
        comparison_data.append({
            "ë ˆë²¨": level,
            "ì„¤ëª…": PRECISION_DESCRIPTIONS[level].split(" - ")[1],
            "ëª©í‘œ ì”¬": f"{get_target_scene_count(level)}ê°œ",
            "ì²˜ë¦¬ ì‹œê°„": TIME_ESTIMATES[level],
            "ì¶”ì²œ": "â­" if level in [5, 6] else ""
        })
    
    # í…Œì´ë¸”ë¡œ í‘œì‹œ
    st.dataframe(
        comparison_data,
        use_container_width=True,
        hide_index=True,
        column_config={
            "ë ˆë²¨": st.column_config.NumberColumn("ë ˆë²¨", width=60),
            "ì„¤ëª…": st.column_config.TextColumn("íŠ¹ì§•", width=200),
            "ëª©í‘œ ì”¬": st.column_config.TextColumn("ì”¬ ê°œìˆ˜", width=80),
            "ì²˜ë¦¬ ì‹œê°„": st.column_config.TextColumn("ì˜ˆìƒ ì‹œê°„", width=100),
            "ì¶”ì²œ": st.column_config.TextColumn("ì¶”ì²œ", width=50)
        }
    )
    
    st.info("""
    ğŸ’¡ **ì‚¬ìš© ê¶Œì¥ì‚¬í•­**
    - **í…ŒìŠ¤íŠ¸/í”„ë¡œí† íƒ€ì…**: ë ˆë²¨ 1-3 (ë¹ ë¥¸ ì²˜ë¦¬)
    - **ì¼ë°˜ì ì¸ ë¶„ì„**: ë ˆë²¨ 5-6 (ê· í˜•ì¡íŒ ì„ íƒ) â­
    - **ì¤‘ìš”í•œ í”„ë¡œì íŠ¸**: ë ˆë²¨ 7-8 (ë†’ì€ ì •í™•ë„)
    - **ìµœê³  í’ˆì§ˆ í•„ìš”ì‹œ**: ë ˆë²¨ 9-10 (ëª¨ë“  íŠ¹ì§• í™œìš©)
    """)


# í—¬í¼ í•¨ìˆ˜ë“¤
def get_target_scene_count(level: int) -> int:
    """ì •ë°€ë„ ë ˆë²¨ë³„ ëª©í‘œ ì”¬ ê°œìˆ˜"""
    if level <= 2:
        return 4
    elif level <= 4:
        return 5
    elif level == 5:
        return 6
    elif level == 6:
        return 7
    elif level == 7:
        return 8
    else:  # 8-10
        return 10


def get_active_features_count(level: int) -> int:
    """ì •ë°€ë„ ë ˆë²¨ë³„ í™œì„± íŠ¹ì§• ìˆ˜"""
    features_count = {
        1: 1,   # color_hist
        2: 2,   # + edge_density
        3: 3,   # + brightness
        4: 4,   # + contrast
        5: 5,   # + color_diversity
        6: 6,   # + texture
        7: 7,   # + spatial_color
        8: 8,   # + perceptual_hash
        9: 8,   # ëª¨ë“  íŠ¹ì§•
        10: 8   # ëª¨ë“  íŠ¹ì§• + ê³ í•´ìƒë„
    }
    return features_count.get(level, 8)


def get_active_features_list(level: int) -> list:
    """ì •ë°€ë„ ë ˆë²¨ë³„ í™œì„± íŠ¹ì§• ëª©ë¡"""
    all_features = {
        'color_hist': 'ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨',
        'edge_density': 'ì—£ì§€ ë°€ë„',
        'brightness': 'ë°ê¸° í†µê³„',
        'contrast': 'ëŒ€ë¹„',
        'color_diversity': 'ìƒ‰ìƒ ë‹¤ì–‘ì„±',
        'texture': 'í…ìŠ¤ì²˜ íŠ¹ì§• (LBP)',
        'spatial_color': 'ê³µê°„ë³„ ìƒ‰ìƒ ë¶„í¬',
        'perceptual_hash': 'ì§€ê°ì  í•´ì‹œ'
    }
    
    active = []
    if level >= 1:
        active.append(all_features['color_hist'])
    if level >= 2:
        active.append(all_features['edge_density'])
    if level >= 3:
        active.append(all_features['brightness'])
    if level >= 4:
        active.append(all_features['contrast'])
    if level >= 5:
        active.append(all_features['color_diversity'])
    if level >= 6:
        active.append(all_features['texture'])
    if level >= 7:
        active.append(all_features['spatial_color'])
    if level >= 8:
        active.append(all_features['perceptual_hash'])
    if level == 10:
        active.append("ê³ í•´ìƒë„ ì²˜ë¦¬ ëª¨ë“œ")
    
    return active
