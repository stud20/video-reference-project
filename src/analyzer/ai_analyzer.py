# src/analyzer/ai_analyzer.py
"""AI ê¸°ë°˜ ì˜ìƒ ì¥ë¥´ ë° ì½˜í…ì¸  ë¶„ì„"""

import os
import base64
import json
from typing import List, Dict, Optional
from pathlib import Path
from openai import OpenAI
from dataclasses import dataclass
from utils.logger import get_logger
from src.models.video import Video, Scene

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    genre: str  # ì˜ìƒ ì¥ë¥´
    reason: str  # íŒë‹¨ ì´ìœ 
    features: str  # íŠ¹ì´ì‚¬í•­
    tags: List[str]  # íƒœê·¸ ëª©ë¡
    format_type: str  # í‘œí˜„ í˜•ì‹ (2D, 3D, ì‹¤ì‚¬ ë“±)
    mood: Optional[str] = None  # ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°
    target_audience: Optional[str] = None  # íƒ€ê²Ÿ ê³ ê°ì¸µ
    confidence: Optional[float] = None  # ë¶„ì„ ì‹ ë¢°ë„

class AIAnalyzer:
    """ì˜ìƒ ë¶„ì„ì„ ìœ„í•œ AI ì—”ì§„"""
    
    # ê°€ëŠ¥í•œ ì¥ë¥´ ëª©ë¡
    GENRES = [
        "2Dì• ë‹ˆë©”ì´ì…˜", "3Dì• ë‹ˆë©”ì´ì…˜", "ëª¨ì…˜ê·¸ë˜í”½", "ì¸í„°ë·°", 
        "ìŠ¤íŒŸê´‘ê³ ", "VLOG", "ìœ íŠœë¸Œì½˜í…ì¸ ", "ë‹¤íë©˜í„°ë¦¬", 
        "ë¸Œëœë“œí•„ë¦„", "TVC", "ë®¤ì§ë¹„ë””ì˜¤", "êµìœ¡ì½˜í…ì¸ ",
        "ì œí’ˆì†Œê°œ", "ì´ë²¤íŠ¸ì˜ìƒ", "ì›¹ë“œë¼ë§ˆ", "ë°”ì´ëŸ´ì˜ìƒ"
    ]
    
    # í‘œí˜„ í˜•ì‹
    FORMAT_TYPES = ["2D", "3D", "ì‹¤ì‚¬", "í˜¼í•©í˜•", "ìŠ¤í†±ëª¨ì…˜", "íƒ€ì´í¬ê·¸ë˜í”¼"]
    
    def __init__(self, api_key: Optional[str] = None):
        self.logger = get_logger(__name__)
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        
        if not self.api_key:
            self.logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            self.client = None
        else:
            self.client = OpenAI(api_key=self.api_key)
    
    def analyze_video(self, video: Video) -> Optional[AnalysisResult]:
        """ë¹„ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰"""
        if not self.client:
            self.logger.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        
        if not video.scenes:
            self.logger.warning("ë¶„ì„í•  ì”¬ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        try:
            # ì´ë¯¸ì§€ ì¤€ë¹„
            image_payloads = self._prepare_images(video.scenes)
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            context = self._prepare_context(video)
            
            # GPT-4 Vision API í˜¸ì¶œ
            response = self._call_gpt4_vision(image_payloads, context)
            
            # ì‘ë‹µ íŒŒì‹±
            result = self._parse_response(response)
            
            # ê²°ê³¼ ì €ì¥
            self._save_analysis_result(video, result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì˜ìƒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def _prepare_images(self, scenes: List[Scene], max_images: int = 10) -> List[Dict]:
        """ë¶„ì„ì„ ìœ„í•œ ì´ë¯¸ì§€ ì¤€ë¹„"""
        image_payloads = []
        
        # ìµœëŒ€ 10ê°œì˜ ëŒ€í‘œ ì”¬ ì„ íƒ
        selected_scenes = scenes[:max_images] if len(scenes) > max_images else scenes
        
        for scene in selected_scenes:
            if os.path.exists(scene.frame_path):
                try:
                    with open(scene.frame_path, "rb") as f:
                        b64_image = base64.b64encode(f.read()).decode("utf-8")
                        image_payloads.append({
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{b64_image}"}
                        })
                except Exception as e:
                    self.logger.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {scene.frame_path} - {e}")
        
        self.logger.info(f"ğŸ“¸ {len(image_payloads)}ê°œ ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ")
        return image_payloads
    
    def _prepare_context(self, video: Video) -> str:
        """ë¶„ì„ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„"""
        context_parts = []
        
        if video.metadata:
            # ì œëª©
            if video.metadata.title:
                context_parts.append(f"ì œëª©: {video.metadata.title}")
            
            # ê¸¸ì´
            if video.metadata.duration:
                minutes = video.metadata.duration // 60
                seconds = video.metadata.duration % 60
                context_parts.append(f"ì˜ìƒ ê¸¸ì´: {minutes}ë¶„ {seconds}ì´ˆ")
            
            # ì—…ë¡œë”
            if video.metadata.uploader:
                context_parts.append(f"ì—…ë¡œë”: {video.metadata.uploader}")
            
            # ì„¤ëª… (ì²˜ìŒ 200ìë§Œ)
            if video.metadata.description:
                desc = video.metadata.description[:200]
                if len(video.metadata.description) > 200:
                    desc += "..."
                context_parts.append(f"ì„¤ëª…: {desc}")
        
        return "\n".join(context_parts)
    
    def _call_gpt4_vision(self, image_payloads: List[Dict], context: str) -> str:
        """GPT-4 Vision API í˜¸ì¶œ"""
        prompt = f"""
{context}

ë‹¤ìŒì€ í•˜ë‚˜ì˜ ì˜ìƒì—ì„œ ì¶”ì¶œí•œ ëŒ€í‘œ ì¥ë©´ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.
ì´ ì˜ìƒì— ëŒ€í•´ ì•„ë˜ í•­ëª©ì„ ëª…í™•í•˜ê²Œ íŒë‹¨í•´ì£¼ì„¸ìš”. ì´ë¯¸ì§€ì™€ ì œê³µëœ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
ì–´ë–»ê²Œë“  ìµœëŒ€í•œ ì •ë³´ë¥¼ ì´ìš©í•´ì„œ 100ì ì´ìƒìœ¼ë¡œ ì‘ì„±í•´ì¤˜

[ë¶„ì„ ìš”ì²­ í•­ëª©]
1. ì˜ìƒì˜ ì¥ë¥´ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”. (í‘œí˜„ ë°©ì‹ê³¼ ëŸ¬ë‹íƒ€ì„ì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨, í•œ ê°€ì§€ë§Œ ì‘ì„±)
   ê°€ëŠ¥í•œ ì¥ë¥´: {', '.join(self.GENRES)}
   
2. ì¥ë¥´ë¡œ íŒë‹¨í•œ ì´ìœ  (ì—°ì¶œ ë°©ì‹, ì •ë³´ ì „ë‹¬ êµ¬ì¡°, ì‹œì²­ìì—ê²Œ ì£¼ëŠ” ì¸ìƒ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ)

3. ì˜ìƒì˜ ì£¼ìš” íŠ¹ì§• ë° íŠ¹ì´ì‚¬í•­
   - ì‹œê°ì  ìŠ¤íƒ€ì¼
   - í¸ì§‘ ë¦¬ë“¬
   - ìƒ‰ê°ê³¼ í†¤
   - ì¹´ë©”ë¼ ì›Œí¬
   
4. ì´ ì˜ìƒì— ì–´ìš¸ë¦¬ëŠ” íƒœê·¸ë¥¼ 10ê°œ ì¶”ì¶œ (ì‰¼í‘œë¡œ êµ¬ë¶„, ë„ì–´ì“°ê¸° ì—†ì´)
   ì˜ˆ: ê°ì„±ì ,ë¯¸ë‹ˆë©€,ë¸Œëœë“œìŠ¤í† ë¦¬,ì Šì€ì¸µíƒ€ê²Ÿ

5. ì˜ìƒì˜ í‘œí˜„ í˜•ì‹: {', '.join(self.FORMAT_TYPES)} ì¤‘ ì„ íƒ

6. ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°ì™€ í†¤ (ì˜ˆ: ë°ê³ ê²½ì¾Œí•œ, ì§„ì¤‘í•˜ê³ ë¬´ê±°ìš´, ê°ì„±ì ì´ê³ ë”°ëœ»í•œ ë“±)

7. ì˜ˆìƒ íƒ€ê²Ÿ ê³ ê°ì¸µ (ì—°ë ¹ëŒ€, ì„±ë³„, ê´€ì‹¬ì‚¬ ë“±)

ë‹µë³€ í˜•ì‹:
A1. [ì¥ë¥´]
A2. [íŒë‹¨ ì´ìœ ]
A3. [íŠ¹ì§• ë° íŠ¹ì´ì‚¬í•­]
A4. [íƒœê·¸1,íƒœê·¸2,íƒœê·¸3,...]
A5. [í‘œí˜„í˜•ì‹]
A6. [ë¶„ìœ„ê¸°ì™€ í†¤]
A7. [íƒ€ê²Ÿ ê³ ê°ì¸µ]
"""
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    *image_payloads
                ]
            }
        ]
        
        self.logger.info("ğŸ¤– GPT-4 Vision API í˜¸ì¶œ ì¤‘...")
        
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=1500,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def _parse_response(self, response: str) -> AnalysisResult:
        """GPT-4 ì‘ë‹µ íŒŒì‹±"""
        lines = response.strip().split('\n')
        parsed = {}
        
        for line in lines:
            if line.startswith('A1.'):
                parsed['genre'] = line.replace('A1.', '').strip()
            elif line.startswith('A2.'):
                parsed['reason'] = line.replace('A2.', '').strip()
            elif line.startswith('A3.'):
                parsed['features'] = line.replace('A3.', '').strip()
            elif line.startswith('A4.'):
                tags_str = line.replace('A4.', '').strip()
                parsed['tags'] = [tag.strip() for tag in tags_str.split(',')]
            elif line.startswith('A5.'):
                parsed['format_type'] = line.replace('A5.', '').strip()
            elif line.startswith('A6.'):
                parsed['mood'] = line.replace('A6.', '').strip()
            elif line.startswith('A7.'):
                parsed['target_audience'] = line.replace('A7.', '').strip()
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        result = AnalysisResult(
            genre=parsed.get('genre', 'ë¯¸ë¶„ë¥˜'),
            reason=parsed.get('reason', ''),
            features=parsed.get('features', ''),
            tags=parsed.get('tags', []),
            format_type=parsed.get('format_type', 'ì‹¤ì‚¬'),
            mood=parsed.get('mood'),
            target_audience=parsed.get('target_audience')
        )
        
        self.logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {result.genre} ({result.format_type})")
        return result
    
    def _save_analysis_result(self, video: Video, result: AnalysisResult):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        # Video ê°ì²´ì— ê²°ê³¼ ì €ì¥
        video.analysis_result = {
            'genre': result.genre,
            'reason': result.reason,
            'features': result.features,
            'tags': result.tags,
            'format_type': result.format_type,
            'mood': result.mood,
            'target_audience': result.target_audience
        }
        
        # JSON íŒŒì¼ë¡œë„ ì €ì¥
        result_path = os.path.join(video.session_dir, "analysis_result.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(video.analysis_result, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {result_path}")