# src/analyzer/ai_analyzer.py
"""AI ê¸°ë°˜ ì˜ìƒ ì¥ë¥´ ë° ì½˜í…ì¸  ë¶„ì„ - ë©”íƒ€ë°ì´í„° ê°•í™” ë²„ì „"""

import os
import base64
import json
import re
from typing import List, Dict, Optional, Any
from pathlib import Path
from openai import OpenAI
from dataclasses import dataclass
from datetime import datetime
from utils.logger import get_logger
from src.models.video import Video, Scene

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    genre: str  # ì˜ìƒ ì¥ë¥´
    reason: str  # íŒë‹¨ ì´ìœ 
    features: str  # íŠ¹ì´ì‚¬í•­
    tags: List[str]  # íƒœê·¸ ëª©ë¡
    format_type: str  # í‘œí˜„ í˜•ì‹ (2D, 3D, ì‹¤ì‚¬ ë“±)
    mood: Optional[str] = None  # ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°
    target_audience: Optional[str] = None  # íƒ€ê²Ÿ ê³ ê°ì¸µ
    confidence: Optional[float] = None  # ë¶„ì„ ì‹ ë¢°ë„

class AIAnalyzer:
    """ì˜ìƒ ë¶„ì„ì„ ìœ„í•œ AI ì—”ì§„"""
    
    # ê°€ëŠ¥í•œ ì¥ë¥´ ëª©ë¡
    GENRES = [
        "2Dì• ë‹ˆë©”ì´ì…˜", "3Dì• ë‹ˆë©”ì´ì…˜", "ëª¨ì…˜ê·¸ë˜í”½", "ì¸í„°ë·°", 
        "ìŠ¤íŒŸê´‘ê³ ", "VLOG", "ìœ íŠœë¸Œì½˜í…ì¸ ", "ë‹¤íë©˜í„°ë¦¬", 
        "ë¸Œëœë“œí•„ë¦„", "TVC", "ë®¤ì§ë¹„ë””ì˜¤", "êµìœ¡ì½˜í…ì¸ ",
        "ì œí’ˆì†Œê°œ", "ì´ë²¤íŠ¸ì˜ìƒ", "ì›¹ë“œë¼ë§ˆ", "ë°”ì´ëŸ´ì˜ìƒ"
    ]
    
    # í‘œí˜„ í˜•ì‹
    FORMAT_TYPES = ["2D", "3D", "ì‹¤ì‚¬", "í˜¼í•©í˜•", "ìŠ¤í†±ëª¨ì…˜", "íƒ€ì´í¬ê·¸ë˜í”¼"]
    
    def __init__(self, api_key: Optional[str] = None):
        self.logger = get_logger(__name__)
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        
        # í† í° ì ˆì•½ì„ ìœ„í•œ ì„¤ì •
        self.max_images = int(os.getenv("MAX_ANALYSIS_IMAGES", "10"))
        self.image_quality = os.getenv("ANALYSIS_IMAGE_QUALITY", "low")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì•ˆì „í•œ ì´ˆê¸°í™”
        self.client = None
        
        if not self.api_key:
            self.logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        else:
            try:
                self.client = OpenAI(api_key=self.api_key)
                self.logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                
            except Exception as e:
                self.logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.logger.error(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                import traceback
                self.logger.error(f"âŒ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                self.client = None
            
    def analyze_video(self, video: Video) -> Optional[AnalysisResult]:
        """ë¹„ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰"""
        if not self.client:
            self.logger.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        
        if not video.scenes:
            self.logger.warning("ë¶„ì„í•  ì”¬ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        try:
            # ë””ë²„ê¹…ìš© ë””ë ‰í† ë¦¬ ìƒì„±
            debug_dir = os.path.join(video.session_dir, "debug")
            os.makedirs(debug_dir, exist_ok=True)
            
            # ì´ë¯¸ì§€ ì¤€ë¹„
            image_payloads = self._prepare_images(video.scenes)
            
            # ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì¶”ê°€
            thumbnail_payload = self._prepare_thumbnail(video)
            if thumbnail_payload:
                # ì¸ë„¤ì¼ì„ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ ì¶”ê°€
                image_payloads.insert(0, thumbnail_payload)
                self.logger.info("ğŸ“¸ ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì¶”ê°€ë¨")
            
            if not image_payloads:
                self.logger.error("ì¤€ë¹„ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„ (í™•ì¥ëœ ë©”íƒ€ë°ì´í„° í¬í•¨)
            context = self._prepare_extended_context(video)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_enhanced_prompt(context, len(image_payloads))
            
            # í”„ë¡¬í”„íŠ¸ ì €ì¥ (ë””ë²„ê¹…ìš©)
            prompt_file = os.path.join(debug_dir, "api_prompt.txt")
            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(f"=== API ìš”ì²­ ì •ë³´ ===\n")
                f.write(f"ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ì´ë¯¸ì§€ ìˆ˜: {len(image_payloads)}\n")
                f.write(f"ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False, indent=2)}\n\n")
                f.write(f"=== í”„ë¡¬í”„íŠ¸ ===\n")
                f.write(prompt)
                f.write(f"\n\n=== ì´ë¯¸ì§€ ì •ë³´ ===\n")
                for i, img in enumerate(image_payloads):
                    f.write(f"ì´ë¯¸ì§€ {i+1}: í’ˆì§ˆ={self.image_quality}\n")
            
            self.logger.info(f"ğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥: {prompt_file}")
            
            # GPT-4 Vision API í˜¸ì¶œ
            response = self._call_gpt4_vision(image_payloads, prompt)
            
            if not response:
                self.logger.error("API ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # API ì‘ë‹µ ì €ì¥ (ë””ë²„ê¹…ìš©)
            response_file = os.path.join(debug_dir, "api_response.txt")
            with open(response_file, 'w', encoding='utf-8') as f:
                f.write(f"=== API ì‘ë‹µ ===\n")
                f.write(f"ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ì‘ë‹µ ê¸¸ì´: {len(response)}ì\n\n")
                f.write(f"=== ì›ë³¸ ì‘ë‹µ ===\n")
                f.write(response)
            
            self.logger.info(f"ğŸ’¾ API ì‘ë‹µ ì €ì¥: {response_file}")
            
            # ì‘ë‹µ íŒŒì‹±
            result = self._parse_response(response)
            
            if not result:
                self.logger.error("íŒŒì‹± ì‹¤íŒ¨")
                return None
            
            # YouTube íƒœê·¸ì™€ ë³‘í•©
            if video.metadata and video.metadata.tags:
                youtube_tags = [tag for tag in video.metadata.tags if tag and len(tag) > 1]
                # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ë³‘í•©
                merged_tags = list(set(result.tags + youtube_tags))
                result.tags = merged_tags[:20]  # ìµœëŒ€ 20ê°œë¡œ ì œí•œ
                self.logger.info(f"ğŸ·ï¸ YouTube íƒœê·¸ {len(youtube_tags)}ê°œ ë³‘í•©ë¨")
            
            # íŒŒì‹± ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
            parsing_file = os.path.join(debug_dir, "parsing_result.txt")
            with open(parsing_file, 'w', encoding='utf-8') as f:
                f.write(f"=== íŒŒì‹± ê²°ê³¼ ===\n")
                f.write(f"ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"ì¥ë¥´: {result.genre}\n")
                f.write(f"íŒë‹¨ ì´ìœ  ({len(result.reason)}ì): {result.reason}\n")
                f.write(f"íŠ¹ì§• ({len(result.features)}ì): {result.features}\n")
                f.write(f"íƒœê·¸ ({len(result.tags)}ê°œ): {', '.join(result.tags)}\n")
                f.write(f"í‘œí˜„í˜•ì‹: {result.format_type}\n")
                f.write(f"ë¶„ìœ„ê¸°: {result.mood}\n")
                f.write(f"íƒ€ê²Ÿ: {result.target_audience}\n")
            
            self.logger.info(f"ğŸ’¾ íŒŒì‹± ê²°ê³¼ ì €ì¥: {parsing_file}")
            
            # ê²°ê³¼ ì €ì¥
            self._save_analysis_result(video, result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì˜ìƒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None
    
    def _prepare_images(self, scenes: List[Scene]) -> List[Dict]:
        """ë¶„ì„ì„ ìœ„í•œ ì´ë¯¸ì§€ ì¤€ë¹„"""
        image_payloads = []
        
        # ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ë§Œí¼ ì„ íƒ
        selected_scenes = scenes[:self.max_images] if len(scenes) > self.max_images else scenes
        
        self.logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¤€ë¹„ ì‹œì‘: {len(selected_scenes)}ê°œ")
        
        for i, scene in enumerate(selected_scenes):
            if not os.path.exists(scene.frame_path):
                self.logger.warning(f"ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {scene.frame_path}")
                continue
            
            try:
                # ì´ë¯¸ì§€ ì½ê¸°
                with open(scene.frame_path, "rb") as f:
                    image_data = base64.b64encode(f.read()).decode('utf-8')
                
                # í˜ì´ë¡œë“œ ìƒì„±
                payload = {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}"
                    }
                }
                
                # detail íŒŒë¼ë¯¸í„°ëŠ” low/highë§Œ ê°€ëŠ¥
                if self.image_quality in ["low", "high"]:
                    payload["image_url"]["detail"] = self.image_quality
                
                image_payloads.append(payload)
                self.logger.debug(f"âœ… ì´ë¯¸ì§€ {i+1} ì¤€ë¹„ ì™„ë£Œ")
                
            except Exception as e:
                self.logger.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {scene.frame_path} - {e}")
        
        self.logger.info(f"ğŸ“¸ {len(image_payloads)}ê°œ ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ")
        return image_payloads
    
    def _prepare_thumbnail(self, video: Video) -> Optional[Dict]:
        """ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì¤€ë¹„"""
        if not video.metadata or not video.metadata.thumbnail:
            return None
        
        # ì¸ë„¤ì¼ì´ ë¡œì»¬ íŒŒì¼ì¸ì§€ í™•ì¸
        thumbnail_path = None
        if os.path.exists(video.metadata.thumbnail):
            thumbnail_path = video.metadata.thumbnail
        else:
            # session_dirì—ì„œ ì¸ë„¤ì¼ ì°¾ê¸°
            possible_extensions = ['.jpg', '.jpeg', '.png', '.webp']
            for ext in possible_extensions:
                test_path = os.path.join(video.session_dir, f"thumbnail{ext}")
                if os.path.exists(test_path):
                    thumbnail_path = test_path
                    break
        
        if not thumbnail_path:
            self.logger.debug("ì¸ë„¤ì¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
        
        try:
            with open(thumbnail_path, "rb") as f:
                image_data = base64.b64encode(f.read()).decode('utf-8')
            
            payload = {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{image_data}",
                    "detail": "low"  # ì¸ë„¤ì¼ì€ low í’ˆì§ˆë¡œ
                }
            }
            
            self.logger.info(f"âœ… ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ: {thumbnail_path}")
            return payload
            
        except Exception as e:
            self.logger.error(f"ì¸ë„¤ì¼ ë¡œë“œ ì‹¤íŒ¨: {thumbnail_path} - {e}")
            return None
    
    def _prepare_extended_context(self, video: Video) -> Dict[str, Any]:
        """í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„"""
        context = {
            "title": "",
            "uploader": "",
            "duration": "",
            "description": "",
            "tags": [],
            "view_count": 0
        }
        
        if video.metadata:
            context["title"] = video.metadata.title or ""
            context["uploader"] = video.metadata.uploader or ""
            
            # ì˜ìƒ ê¸¸ì´ í¬ë§·íŒ…
            if video.metadata.duration:
                minutes = int(video.metadata.duration // 60)
                seconds = int(video.metadata.duration % 60)
                context["duration"] = f"{minutes}ë¶„ {seconds}ì´ˆ"
            
            context["description"] = video.metadata.description[:500] if video.metadata.description else ""  # ì„¤ëª…ì€ 500ìë¡œ ì œí•œ
            context["tags"] = video.metadata.tags[:10] if video.metadata.tags else []  # ìƒìœ„ 10ê°œ íƒœê·¸ë§Œ
            context["view_count"] = video.metadata.view_count or 0
        
        return context
    
    def _create_enhanced_prompt(self, context: Dict[str, Any], image_count: int) -> str:
        """ê°•í™”ëœ API í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # ë©”íƒ€ë°ì´í„° ì •ë³´ êµ¬ì„±
        metadata_info = []
        
        if context["title"]:
            metadata_info.append(f"ì œëª©: {context['title']}")
        
        if context["uploader"]:
            metadata_info.append(f"ì—…ë¡œë”/ì±„ë„: {context['uploader']}")
        
        if context["duration"]:
            metadata_info.append(f"ì˜ìƒ ê¸¸ì´: {context['duration']}")
        
        if context["view_count"] > 0:
            metadata_info.append(f"ì¡°íšŒìˆ˜: {context['view_count']:,}íšŒ")
        
        if context["tags"]:
            metadata_info.append(f"YouTube íƒœê·¸: {', '.join(context['tags'])}")
        
        metadata_text = "\n".join(metadata_info)
        
        # ì„¤ëª… í…ìŠ¤íŠ¸ ì¶”ê°€
        description_text = ""
        if context["description"]:
            description_text = f"\n\nì˜ìƒ ì„¤ëª…:\n{context['description']}"
        
        prompt = f"""ì˜ìƒ ë©”íƒ€ë°ì´í„°:
{metadata_text}{description_text}

ìœ„ ì˜ìƒì—ì„œ ì¶”ì¶œí•œ {image_count}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. 
ì²« ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ì¸ë„¤ì¼ì´ë©°, ë‚˜ë¨¸ì§€ëŠ” ì˜ìƒì˜ ëŒ€í‘œ ì¥ë©´ë“¤ì…ë‹ˆë‹¤.

ì œê³µëœ ë©”íƒ€ë°ì´í„°(ì œëª©, ì„¤ëª…, íƒœê·¸ ë“±)ë¥¼ ì°¸ê³ í•˜ì—¬ ë” ì •í™•í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë˜,
ì‹¤ì œ ì´ë¯¸ì§€ ë‚´ìš©ì´ ë©”íƒ€ë°ì´í„°ì™€ ë‹¤ë¥¼ ê²½ìš° ì´ë¯¸ì§€ ë‚´ìš©ì„ ìš°ì„ ì‹œí•´ì£¼ì„¸ìš”.

ë‹¤ìŒ 7ê°œ í•­ëª©ì„ ëª¨ë‘ ì‘ì„±í•´ì£¼ì„¸ìš”. ê° í•­ëª©ì˜ ë‹µë³€ì—ëŠ” "ì¥ë¥´ íŒë‹¨ ì´ìœ :", "ì˜ìƒì˜ íŠ¹ì§•:" ê°™ì€ ë ˆì´ë¸”ì„ í¬í•¨í•˜ì§€ ë§ê³  ë‚´ìš©ë§Œ ì‘ì„±í•˜ì„¸ìš”.

ë¶„ì„ í•­ëª©:
A1. ì˜ìƒ ì¥ë¥´ (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ): {', '.join(self.GENRES)}
A2. ì¥ë¥´ íŒë‹¨ ì´ìœ  (ì‹œê°ì  íŠ¹ì§•, ì—°ì¶œ ìŠ¤íƒ€ì¼, ì •ë³´ ì „ë‹¬ ë°©ì‹, ë©”íƒ€ë°ì´í„° ë“±ì„ ì¢…í•©í•˜ì—¬ 200ì ì´ìƒ ìƒì„¸íˆ ì„¤ëª…)
A3. ì˜ìƒì˜ íŠ¹ì§• ë° íŠ¹ì´ì‚¬í•­ (ìƒ‰ê°, í¸ì§‘, ì¹´ë©”ë¼ì›Œí¬, ë¶„ìœ„ê¸°, ë©”ì‹œì§€ ë“±ì„ 200ì ì´ìƒ ìƒì„¸íˆ ì„¤ëª…)
A4. ê´€ë ¨ íƒœê·¸ 10ê°œ ì´ìƒ (ì‰¼í‘œë¡œ êµ¬ë¶„, # ê¸°í˜¸ ì—†ì´, YouTube íƒœê·¸ì™€ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ íƒœê·¸ ìœ„ì£¼ë¡œ)
A5. í‘œí˜„í˜•ì‹ (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ): {', '.join(self.FORMAT_TYPES)}
A6. ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°ì™€ í†¤
A7. ì˜ˆìƒ íƒ€ê²Ÿ ê³ ê°ì¸µ

ì¤‘ìš”: ê° ë‹µë³€ì€ ë ˆì´ë¸” ì—†ì´ ë‚´ìš©ë§Œ ì‘ì„±í•˜ì„¸ìš”."""
        
        return prompt
    
    def _call_gpt4_vision(self, image_payloads: List[Dict], prompt: str) -> Optional[str]:
        """GPT-4 Vision API í˜¸ì¶œ"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê´‘ê³  ì˜ìƒ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì´ë¯¸ì§€ë“¤ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì˜ìƒì˜ ì¥ë¥´, íŠ¹ì§•, íƒ€ê²Ÿ ë“±ì„ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. ë©”íƒ€ë°ì´í„°ëŠ” ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ ì´ë¯¸ì§€ ë‚´ìš©ì„ ìš°ì„ ì‹œí•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        *image_payloads
                    ]
                }
            ]
            
            self.logger.info("ğŸ¤– GPT-4 Vision API í˜¸ì¶œ ì¤‘...")
            
            # ëª¨ë¸ ì„ íƒ
            model = os.getenv("OPENAI_MODEL", "gpt-4o")
            self.logger.info(f"ì‚¬ìš© ëª¨ë¸: {model}")
            
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=2000,
                temperature=0.7
            )
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
            if hasattr(response, 'usage'):
                self.logger.info(f"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰ - ì…ë ¥: {response.usage.prompt_tokens}, ì¶œë ¥: {response.usage.completion_tokens}")
            
            content = response.choices[0].message.content
            self.logger.info(f"ğŸ“ API ì‘ë‹µ ê¸¸ì´: {len(content)}ì")
            
            return content
            
        except Exception as e:
            self.logger.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _parse_response(self, response: str) -> Optional[AnalysisResult]:
        """GPT-4 ì‘ë‹µ íŒŒì‹± - ê°œì„ ëœ ë²„ì „"""
        if not response or len(response) < 100:
            self.logger.error(f"ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŒ: {len(response) if response else 0}ì")
            return None
        
        self.logger.info("ğŸ“ ì‘ë‹µ íŒŒì‹± ì‹œì‘...")
        
        # ì‘ë‹µì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        lines = response.strip().split('\n')
        
        # ë¹ˆ ì¤„ ì œê±°
        lines = [line.strip() for line in lines if line.strip()]
        
        # íŒŒì‹± ê²°ê³¼ ì´ˆê¸°í™”
        parsed = {
            'genre': '',
            'reason': '',
            'features': '',
            'tags': [],
            'format_type': '',
            'mood': '',
            'target_audience': ''
        }
        
        # í…ìŠ¤íŠ¸ë¥¼ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬ (ë‘ ì¤„ ì´ìƒì˜ ë¹ˆ ì¤„ë¡œ êµ¬ë¶„)
        sections = response.strip().split('\n\n')
        
        # ì„¹ì…˜ì´ 7ê°œê°€ ì•„ë‹ˆë©´ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„
        if len(sections) < 7:
            # ê° ì¤„ì„ í•˜ë‚˜ì”© í™•ì¸í•˜ë©´ì„œ íŒŒì‹±
            self.logger.info(f"ì„¹ì…˜ ìˆ˜: {len(sections)}, ëŒ€ì²´ íŒŒì‹± ë°©ì‹ ì‚¬ìš©")
            
            # ì²« ë²ˆì§¸ ì¤„ì€ ì¥ë¥´
            if lines:
                parsed['genre'] = lines[0].strip()
                self.logger.debug(f"ì¥ë¥´: {parsed['genre']}")
            
            # ë‚˜ë¨¸ì§€ ë‚´ìš©ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì³ì„œ íŒŒì‹±
            remaining_text = '\n'.join(lines[1:])
            
            # ê° ì„¹ì…˜ì„ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œë‚˜ íŒ¨í„´ ì°¾ê¸°
            # ê¸´ í…ìŠ¤íŠ¸ëŠ” reasonê³¼ featuresì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            paragraphs = [p.strip() for p in remaining_text.split('\n\n') if p.strip()]
            
            if len(paragraphs) >= 6:
                parsed['reason'] = paragraphs[0]
                parsed['features'] = paragraphs[1]
                
                # íƒœê·¸ ì°¾ê¸° (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸)
                for p in paragraphs[2:]:
                    if ',' in p and len(p.split(',')) > 5:
                        parsed['tags'] = [tag.strip() for tag in p.split(',')]
                        break
                
                # í‘œí˜„í˜•ì‹ ì°¾ê¸° (FORMAT_TYPES ì¤‘ í•˜ë‚˜)
                for p in paragraphs:
                    for fmt in self.FORMAT_TYPES:
                        if fmt in p and len(p) < 20:  # ì§§ì€ í…ìŠ¤íŠ¸
                            parsed['format_type'] = fmt
                            break
                
                # ë‚˜ë¨¸ì§€ ì§§ì€ ë¬¸ì¥ë“¤ì€ moodì™€ target_audience
                short_paragraphs = [p for p in paragraphs if len(p) < 200 and p not in [parsed['reason'], parsed['features']]]
                if len(short_paragraphs) >= 2:
                    parsed['mood'] = short_paragraphs[-2]
                    parsed['target_audience'] = short_paragraphs[-1]
        
        else:
            # ì„¹ì…˜ì´ 7ê°œ ì´ìƒì´ë©´ ìˆœì„œëŒ€ë¡œ í• ë‹¹
            parsed['genre'] = sections[0].strip()
            parsed['reason'] = sections[1].strip()
            parsed['features'] = sections[2].strip()
            
            # íƒœê·¸ ì²˜ë¦¬
            tags_text = sections[3].strip()
            parsed['tags'] = [tag.strip() for tag in tags_text.split(',')]
            
            parsed['format_type'] = sections[4].strip()
            parsed['mood'] = sections[5].strip()
            parsed['target_audience'] = sections[6].strip()
        
        # íŒŒì‹± ê²°ê³¼ ê²€ì¦ ë° ì •ë¦¬
        if not parsed['genre']:
            self.logger.error("ì¥ë¥´ê°€ íŒŒì‹±ë˜ì§€ ì•ŠìŒ")
            return None
        
        # ì¥ë¥´ê°€ ìœ íš¨í•œì§€ í™•ì¸
        if parsed['genre'] not in self.GENRES:
            self.logger.warning(f"íŒŒì‹±ëœ ì¥ë¥´ê°€ ëª©ë¡ì— ì—†ìŒ: {parsed['genre']}")
            # ê°€ì¥ ìœ ì‚¬í•œ ì¥ë¥´ ì°¾ê¸° (ì˜µì…˜)
        
        # ê²°ê³¼ ìƒì„±
        result = AnalysisResult(
            genre=parsed['genre'],
            reason=parsed['reason'] or 'ë¶„ì„ ë‚´ìš© ì—†ìŒ',
            features=parsed['features'] or 'ë¶„ì„ ë‚´ìš© ì—†ìŒ',
            tags=parsed['tags'] or [],
            format_type=parsed['format_type'] or 'ì‹¤ì‚¬',
            mood=parsed['mood'],
            target_audience=parsed['target_audience']
        )
        
        self.logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ - ì¥ë¥´: {result.genre}, íƒœê·¸ ìˆ˜: {len(result.tags)}")
        
        return result
    
    def _save_analysis_result(self, video: Video, result: AnalysisResult):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        # Video ê°ì²´ì— ê²°ê³¼ ì €ì¥ (DB ìŠ¤í‚¤ë§ˆì— ë§ê²Œ í‚¤ ì´ë¦„ ë³€ê²½)
        video.analysis_result = {
            'genre': result.genre,
            'reasoning': result.reason,  # reason -> reasoning
            'features': result.features,
            'tags': result.tags,
            'expression_style': result.format_type,  # format_type -> expression_style
            'mood_tone': result.mood,  # mood -> mood_tone
            'target_audience': result.target_audience,
            'model_used': os.getenv("OPENAI_MODEL", "gpt-4o"),
            'analysis_date': datetime.now().isoformat()
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        result_path = os.path.join(video.session_dir, "analysis_result.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(video.analysis_result, f, ensure_ascii=False, indent=2)
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë„ ì €ì¥ (ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹)
        result_text_path = os.path.join(video.session_dir, "analysis_result.txt")
        with open(result_text_path, 'w', encoding='utf-8') as f:
            f.write(f"=== AI ì˜ìƒ ë¶„ì„ ê²°ê³¼ ===\n\n")
            f.write(f"[ì¥ë¥´]: {result.genre}\n\n")
            f.write(f"[íŒë‹¨ ì´ìœ ]:\n{result.reason}\n\n")
            f.write(f"[íŠ¹ì§• ë° íŠ¹ì´ì‚¬í•­]:\n{result.features}\n\n")
            f.write(f"[íƒœê·¸]: {', '.join(result.tags)}\n\n")
            f.write(f"[í‘œí˜„í˜•ì‹]: {result.format_type}\n\n")
            f.write(f"[ë¶„ìœ„ê¸°ì™€ í†¤]: {result.mood}\n\n")
            f.write(f"[íƒ€ê²Ÿ ê³ ê°ì¸µ]: {result.target_audience}\n")
        
        self.logger.info(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {result_path}")