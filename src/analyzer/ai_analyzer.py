# src/analyzer/ai_analyzer.py
"""AI ê¸°ë°˜ ì˜ìƒ ì¥ë¥´ ë° ì½˜í…ì¸  ë¶„ì„"""

import os
import base64
import json
import re
from typing import List, Dict, Optional
from pathlib import Path
from openai import OpenAI
from dataclasses import dataclass
from datetime import datetime
from utils.logger import get_logger
from src.models.video import Video, Scene

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    genre: str  # ì˜ìƒ ì¥ë¥´
    reason: str  # íŒë‹¨ ì´ìœ 
    features: str  # íŠ¹ì´ì‚¬í•­
    tags: List[str]  # íƒœê·¸ ëª©ë¡
    format_type: str  # í‘œí˜„ í˜•ì‹ (2D, 3D, ì‹¤ì‚¬ ë“±)
    mood: Optional[str] = None  # ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°
    target_audience: Optional[str] = None  # íƒ€ê²Ÿ ê³ ê°ì¸µ
    confidence: Optional[float] = None  # ë¶„ì„ ì‹ ë¢°ë„

class AIAnalyzer:
    """ì˜ìƒ ë¶„ì„ì„ ìœ„í•œ AI ì—”ì§„"""
    
    # ê°€ëŠ¥í•œ ì¥ë¥´ ëª©ë¡
    GENRES = [
        "2Dì• ë‹ˆë©”ì´ì…˜", "3Dì• ë‹ˆë©”ì´ì…˜", "ëª¨ì…˜ê·¸ë˜í”½", "ì¸í„°ë·°", 
        "ìŠ¤íŒŸê´‘ê³ ", "VLOG", "ìœ íŠœë¸Œì½˜í…ì¸ ", "ë‹¤íë©˜í„°ë¦¬", 
        "ë¸Œëœë“œí•„ë¦„", "TVC", "ë®¤ì§ë¹„ë””ì˜¤", "êµìœ¡ì½˜í…ì¸ ",
        "ì œí’ˆì†Œê°œ", "ì´ë²¤íŠ¸ì˜ìƒ", "ì›¹ë“œë¼ë§ˆ", "ë°”ì´ëŸ´ì˜ìƒ"
    ]
    
    # í‘œí˜„ í˜•ì‹
    FORMAT_TYPES = ["2D", "3D", "ì‹¤ì‚¬", "í˜¼í•©í˜•", "ìŠ¤í†±ëª¨ì…˜", "íƒ€ì´í¬ê·¸ë˜í”¼"]
    
    def __init__(self, api_key: Optional[str] = None):
        self.logger = get_logger(__name__)
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        
        # í† í° ì ˆì•½ì„ ìœ„í•œ ì„¤ì •
        self.max_images = int(os.getenv("MAX_ANALYSIS_IMAGES", "10"))
        self.image_quality = os.getenv("ANALYSIS_IMAGE_QUALITY", "low")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì•ˆì „í•œ ì´ˆê¸°í™”
        self.client = None
        
        if not self.api_key:
            self.logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        else:
            try:
                self.client = OpenAI(api_key=self.api_key)
                self.logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                
                # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì˜µì…˜)
                # self._test_connection()
                
            except Exception as e:
                self.logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.logger.error(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                import traceback
                self.logger.error(f"âŒ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                self.client = None

    def _test_connection(self):
        """OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸ (ì˜µì…˜)"""
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1
            )
            self.logger.info("âœ… OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            # í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨í•´ë„ í´ë¼ì´ì–¸íŠ¸ëŠ” ìœ ì§€
            
    def analyze_video(self, video: Video) -> Optional[AnalysisResult]:
        """ë¹„ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰"""
        if not self.client:
            self.logger.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        
        if not video.scenes:
            self.logger.warning("ë¶„ì„í•  ì”¬ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        try:
            # ë””ë²„ê¹…ìš© ë””ë ‰í† ë¦¬ ìƒì„±
            debug_dir = os.path.join(video.session_dir, "debug")
            os.makedirs(debug_dir, exist_ok=True)
            
            # ì´ë¯¸ì§€ ì¤€ë¹„
            image_payloads = self._prepare_images(video.scenes)
            
            if not image_payloads:
                self.logger.error("ì¤€ë¹„ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            context = self._prepare_context(video)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_prompt(context, len(image_payloads))
            
            # í”„ë¡¬í”„íŠ¸ ì €ì¥ (ë””ë²„ê¹…ìš©)
            prompt_file = os.path.join(debug_dir, "api_prompt.txt")
            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(f"=== API ìš”ì²­ ì •ë³´ ===\n")
                f.write(f"ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ì´ë¯¸ì§€ ìˆ˜: {len(image_payloads)}\n")
                f.write(f"ì»¨í…ìŠ¤íŠ¸: {context}\n\n")
                f.write(f"=== í”„ë¡¬í”„íŠ¸ ===\n")
                f.write(prompt)
                f.write(f"\n\n=== ì´ë¯¸ì§€ ì •ë³´ ===\n")
                for i, img in enumerate(image_payloads):
                    f.write(f"ì´ë¯¸ì§€ {i+1}: í’ˆì§ˆ={self.image_quality}\n")
            
            self.logger.info(f"ğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥: {prompt_file}")
            
            # GPT-4 Vision API í˜¸ì¶œ
            response = self._call_gpt4_vision(image_payloads, prompt)
            
            if not response:
                self.logger.error("API ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # API ì‘ë‹µ ì €ì¥ (ë””ë²„ê¹…ìš©)
            response_file = os.path.join(debug_dir, "api_response.txt")
            with open(response_file, 'w', encoding='utf-8') as f:
                f.write(f"=== API ì‘ë‹µ ===\n")
                f.write(f"ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ì‘ë‹µ ê¸¸ì´: {len(response)}ì\n\n")
                f.write(f"=== ì›ë³¸ ì‘ë‹µ ===\n")
                f.write(response)
            
            self.logger.info(f"ğŸ’¾ API ì‘ë‹µ ì €ì¥: {response_file}")
            
            # ì‘ë‹µ íŒŒì‹±
            result = self._parse_response(response)
            
            if not result:
                self.logger.error("íŒŒì‹± ì‹¤íŒ¨")
                return None
            
            # íŒŒì‹± ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
            parsing_file = os.path.join(debug_dir, "parsing_result.txt")
            with open(parsing_file, 'w', encoding='utf-8') as f:
                f.write(f"=== íŒŒì‹± ê²°ê³¼ ===\n")
                f.write(f"ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"ì¥ë¥´: {result.genre}\n")
                f.write(f"íŒë‹¨ ì´ìœ  ({len(result.reason)}ì): {result.reason}\n")
                f.write(f"íŠ¹ì§• ({len(result.features)}ì): {result.features}\n")
                f.write(f"íƒœê·¸ ({len(result.tags)}ê°œ): {', '.join(result.tags)}\n")
                f.write(f"í‘œí˜„í˜•ì‹: {result.format_type}\n")
                f.write(f"ë¶„ìœ„ê¸°: {result.mood}\n")
                f.write(f"íƒ€ê²Ÿ: {result.target_audience}\n")
            
            self.logger.info(f"ğŸ’¾ íŒŒì‹± ê²°ê³¼ ì €ì¥: {parsing_file}")
            
            # ê²°ê³¼ ì €ì¥
            self._save_analysis_result(video, result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì˜ìƒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None
    
    def _prepare_images(self, scenes: List[Scene]) -> List[Dict]:
        """ë¶„ì„ì„ ìœ„í•œ ì´ë¯¸ì§€ ì¤€ë¹„"""
        image_payloads = []
        
        # ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ë§Œí¼ ì„ íƒ
        selected_scenes = scenes[:self.max_images] if len(scenes) > self.max_images else scenes
        
        self.logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¤€ë¹„ ì‹œì‘: {len(selected_scenes)}ê°œ")
        
        for i, scene in enumerate(selected_scenes):
            if not os.path.exists(scene.frame_path):
                self.logger.warning(f"ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {scene.frame_path}")
                continue
            
            try:
                # ì´ë¯¸ì§€ ì½ê¸°
                with open(scene.frame_path, "rb") as f:
                    image_data = base64.b64encode(f.read()).decode('utf-8')
                
                # í˜ì´ë¡œë“œ ìƒì„±
                payload = {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}"
                    }
                }
                
                # detail íŒŒë¼ë¯¸í„°ëŠ” low/highë§Œ ê°€ëŠ¥
                if self.image_quality in ["low", "high"]:
                    payload["image_url"]["detail"] = self.image_quality
                
                image_payloads.append(payload)
                self.logger.debug(f"âœ… ì´ë¯¸ì§€ {i+1} ì¤€ë¹„ ì™„ë£Œ")
                
            except Exception as e:
                self.logger.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {scene.frame_path} - {e}")
        
        self.logger.info(f"ğŸ“¸ {len(image_payloads)}ê°œ ì´ë¯¸ì§€ ì¤€ë¹„ ì™„ë£Œ")
        return image_payloads
    
    def _prepare_context(self, video: Video) -> str:
        """ë¶„ì„ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„"""
        context_parts = []
        
        if video.metadata:
            if video.metadata.title:
                context_parts.append(f"ì œëª©: {video.metadata.title}")
            
            if video.metadata.duration:
                minutes = video.metadata.duration // 60
                seconds = video.metadata.duration % 60
                context_parts.append(f"ê¸¸ì´: {minutes}ë¶„ {seconds}ì´ˆ")
        
        return " / ".join(context_parts) if context_parts else "ì •ë³´ ì—†ìŒ"
    
    def _create_prompt(self, context: str, image_count: int) -> str:
        """API í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""ì˜ìƒ ì •ë³´: {context}

ìœ„ ì˜ìƒì—ì„œ ì¶”ì¶œí•œ {image_count}ê°œì˜ ëŒ€í‘œ ì¥ë©´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ 7ê°œ í•­ëª©ì„ ëª¨ë‘ ì‘ì„±í•´ì£¼ì„¸ìš”. A2ì™€ A3ëŠ” ë°˜ë“œì‹œ 200ì ì´ìƒ ìƒì„¸íˆ ì‘ì„±í•˜ì„¸ìš”.

ë¶„ì„ í•­ëª©:
A1. ì˜ìƒ ì¥ë¥´ (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ): {', '.join(self.GENRES)}
A2. ì¥ë¥´ íŒë‹¨ ì´ìœ  (ì‹œê°ì  íŠ¹ì§•, ì—°ì¶œ ìŠ¤íƒ€ì¼, ì •ë³´ ì „ë‹¬ ë°©ì‹ ë“±ì„ 200ì ì´ìƒ ìƒì„¸íˆ ì„¤ëª…)
A3. ì˜ìƒì˜ íŠ¹ì§• ë° íŠ¹ì´ì‚¬í•­ (ìƒ‰ê°, í¸ì§‘, ì¹´ë©”ë¼ì›Œí¬, ë¶„ìœ„ê¸° ë“±ì„ 200ì ì´ìƒ ìƒì„¸íˆ ì„¤ëª…)
A4. ê´€ë ¨ íƒœê·¸ 10ê°œ ì´ìƒ (ì‰¼í‘œë¡œ êµ¬ë¶„)
A5. í‘œí˜„í˜•ì‹ (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ): {', '.join(self.FORMAT_TYPES)}
A6. ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°ì™€ í†¤
A7. ì˜ˆìƒ íƒ€ê²Ÿ ê³ ê°ì¸µ

ìœ„ í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        return prompt
    
    def _call_gpt4_vision(self, image_payloads: List[Dict], prompt: str) -> Optional[str]:
        """GPT-4 Vision API í˜¸ì¶œ"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê´‘ê³  ì˜ìƒ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì´ë¯¸ì§€ë“¤ì„ ë³´ê³  ì˜ìƒì˜ ì¥ë¥´, íŠ¹ì§•, íƒ€ê²Ÿ ë“±ì„ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        *image_payloads
                    ]
                }
            ]
            
            self.logger.info("ğŸ¤– GPT-4 Vision API í˜¸ì¶œ ì¤‘...")
            
            # ëª¨ë¸ ì„ íƒ
            model = os.getenv("OPENAI_MODEL", "gpt-4o")
            self.logger.info(f"ì‚¬ìš© ëª¨ë¸: {model}")
            
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=2000,
                temperature=0.7
            )
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
            if hasattr(response, 'usage'):
                self.logger.info(f"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰ - ì…ë ¥: {response.usage.prompt_tokens}, ì¶œë ¥: {response.usage.completion_tokens}")
            
            content = response.choices[0].message.content
            self.logger.info(f"ğŸ“ API ì‘ë‹µ ê¸¸ì´: {len(content)}ì")
            
            return content
            
        except Exception as e:
            self.logger.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _parse_response(self, response: str) -> Optional[AnalysisResult]:
        """GPT-4 ì‘ë‹µ íŒŒì‹±"""
        if not response or len(response) < 100:
            self.logger.error(f"ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŒ: {len(response) if response else 0}ì")
            return None
        
        self.logger.info("ğŸ“ ì‘ë‹µ íŒŒì‹± ì‹œì‘...")
        
        # íŒŒì‹± ê²°ê³¼ ì´ˆê¸°í™”
        parsed = {
            'genre': '',
            'reason': '',
            'features': '',
            'tags': [],
            'format_type': '',
            'mood': '',
            'target_audience': ''
        }
        
        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŒŒì‹±
        patterns = {
            'genre': r'A1[\.:\s]*([^\n]+)',
            'reason': r'A2[\.:\s]*([\s\S]+?)(?=A3[\.:\s]|$)',
            'features': r'A3[\.:\s]*([\s\S]+?)(?=A4[\.:\s]|$)',
            'tags': r'A4[\.:\s]*([\s\S]+?)(?=A5[\.:\s]|$)',
            'format_type': r'A5[\.:\s]*([^\n]+)',
            'mood': r'A6[\.:\s]*([\s\S]+?)(?=A7[\.:\s]|$)',
            'target_audience': r'A7[\.:\s]*([\s\S]+?)$'
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, response, re.MULTILINE | re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                
                # ëŒ€ê´„í˜¸ ì œê±°
                value = value.strip('[]')
                
                if key == 'tags':
                    # íƒœê·¸ëŠ” ì‰¼í‘œë¡œ ë¶„ë¦¬
                    parsed[key] = [tag.strip() for tag in value.split(',') if tag.strip()]
                else:
                    parsed[key] = value
                
                self.logger.debug(f"íŒŒì‹± - {key}: {value[:50]}...")
        
        # íŒŒì‹± ê²°ê³¼ ê²€ì¦
        if not parsed['genre']:
            self.logger.error("ì¥ë¥´ê°€ íŒŒì‹±ë˜ì§€ ì•ŠìŒ")
            return None
        
        # ê²°ê³¼ ìƒì„±
        result = AnalysisResult(
            genre=parsed['genre'],
            reason=parsed['reason'] or 'ë¶„ì„ ë‚´ìš© ì—†ìŒ',
            features=parsed['features'] or 'ë¶„ì„ ë‚´ìš© ì—†ìŒ',
            tags=parsed['tags'] or [],
            format_type=parsed['format_type'] or 'ì‹¤ì‚¬',
            mood=parsed['mood'],
            target_audience=parsed['target_audience']
        )
        
        self.logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ - ì¥ë¥´: {result.genre}, íƒœê·¸ ìˆ˜: {len(result.tags)}")
        
        return result
    
    def _save_analysis_result(self, video: Video, result: AnalysisResult):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        # Video ê°ì²´ì— ê²°ê³¼ ì €ì¥
        video.analysis_result = {
            'genre': result.genre,
            'reason': result.reason,
            'features': result.features,
            'tags': result.tags,
            'format_type': result.format_type,
            'mood': result.mood,
            'target_audience': result.target_audience
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        result_path = os.path.join(video.session_dir, "analysis_result.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(video.analysis_result, f, ensure_ascii=False, indent=2)
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë„ ì €ì¥
        result_text_path = os.path.join(video.session_dir, "analysis_result.txt")
        with open(result_text_path, 'w', encoding='utf-8') as f:
            f.write(f"=== AI ì˜ìƒ ë¶„ì„ ê²°ê³¼ ===\n\n")
            f.write(f"[ì¥ë¥´]: {result.genre}\n\n")
            f.write(f"[íŒë‹¨ ì´ìœ ]:\n{result.reason}\n\n")
            f.write(f"[íŠ¹ì§• ë° íŠ¹ì´ì‚¬í•­]:\n{result.features}\n\n")
            f.write(f"[íƒœê·¸]: {', '.join(result.tags)}\n\n")
            f.write(f"[í‘œí˜„í˜•ì‹]: {result.format_type}\n\n")
            f.write(f"[ë¶„ìœ„ê¸°ì™€ í†¤]: {result.mood}\n\n")
            f.write(f"[íƒ€ê²Ÿ ê³ ê°ì¸µ]: {result.target_audience}\n")
        
        self.logger.info(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {result_path}")