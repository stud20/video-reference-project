# src/pipeline/stages/extraction_stage.py
"""ì”¬ ì¶”ì¶œ ìŠ¤í…Œì´ì§€"""

from core.video.scene_detector import SceneExtractor
from core.video.models import Scene

from ..pipeline import PipelineStage, PipelineContext


class SceneExtractionStage(PipelineStage):
    """ì”¬ ì¶”ì¶œ"""
    
    def __init__(self):
        super().__init__("scene_extraction")
        self.extractor = SceneExtractor()
    
    def can_skip(self, context: PipelineContext) -> bool:
        """ìºì‹œ íˆíŠ¸ ì‹œ ìŠ¤í‚µ"""
        return context.stage_results.get("cache_hit", False)
    
    def execute(self, context: PipelineContext) -> PipelineContext:
        """ì”¬ ì¶”ì¶œ ì‹¤í–‰"""
        self.update_progress(0, "ğŸï¸ ì¥ë©´ ì¶”ì¶œ ì‹œì‘...", context)
        
        video = context.video_object
        
        # ì”¬ ì¶”ì¶œ (ë‚´ë¶€ progress callback ì—†ì´)
        is_short_form = video.metadata.is_short_form if video.metadata else False
        scenes_result = self.extractor.extract_scenes(
            video.local_path,
            video.session_id,
            progress_callback=None,
            is_short_form=is_short_form
        )
        
        # Scene ê°ì²´ë¡œ ë³€í™˜
        video.scenes = []
        
        if isinstance(scenes_result, dict):
            # ìƒˆë¡œìš´ ë°˜í™˜ í˜•ì‹
            all_scenes = scenes_result.get('all_scenes', [])
            grouped_scenes = scenes_result.get('grouped_scenes', [])
            
            self.logger.info(f"ğŸ“Š ì”¬ ì¶”ì¶œ ê²°ê³¼: ì „ì²´ {len(all_scenes)}ê°œ, ê·¸ë£¹í™” {len(grouped_scenes)}ê°œ")
            
            # AI ë¶„ì„ì„ ìœ„í•´ ê·¸ë£¹í™”ëœ ì”¬ ì‚¬ìš©
            scenes_to_use = grouped_scenes if grouped_scenes else all_scenes[:10]
            
            for scene_data in scenes_to_use:
                if isinstance(scene_data, Scene):
                    video.scenes.append(scene_data)
                elif isinstance(scene_data, dict):
                    scene = Scene(
                        timestamp=scene_data.get('timestamp', 0.0),
                        frame_path=scene_data.get('frame_path', '') or scene_data.get('path', ''),
                        scene_type=scene_data.get('type', 'mid')
                    )
                    video.scenes.append(scene)
        
        context.scenes = video.scenes
        
        self.update_progress(100, f"âœ… {len(video.scenes)}ê°œ ì”¬ ì¶”ì¶œ ì™„ë£Œ", context)
        
        return context
