# core/workflow/stages/ai_analyzer.py
"""AI ë¶„ì„ ìŠ¤í…Œì´ì§€"""

import os
from core.analysis import VideoAnalyzer
from core.analysis.providers import OpenAIProvider, ClaudeProvider, GeminiProvider
from core.database import VideoRepository

from ..pipeline import PipelineStage, PipelineContext


class AIAnalysisStage(PipelineStage):
    """AI ì˜ìƒ ë¶„ì„"""
    
    def __init__(self, provider_name: str = "openai"):
        super().__init__("ai_analysis")
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ëª… í™•ì¸
        model_name = os.getenv("AI_MODEL_NAME", "gpt-4o")
        self.model_name = model_name
        self.provider_name = self._get_provider_from_model(model_name)
        self.analyzer = self._create_analyzer_for_model(model_name)
        self.db = VideoRepository()
    
    def _get_provider_from_model(self, model_name: str) -> str:
        """ëª¨ë¸ëª…ì—ì„œ Provider ì´ë¦„ ì¶”ì¶œ"""
        if "claude" in model_name.lower():
            return "claude"
        elif "gemini" in model_name.lower():
            return "gemini"
        else:
            return "openai"
    
    def _create_analyzer_for_model(self, model_name: str) -> VideoAnalyzer:
        """ëª¨ë¸ëª…ì— ë”°ë¥¸ Analyzer ìƒì„±"""
        # ëª¨ë¸ë³„ Provider ì„¤ì •
        if "claude" in model_name.lower():
            provider = ClaudeProvider(model=model_name)
        elif "gemini" in model_name.lower():
            provider = GeminiProvider(model=model_name)
        else:
            provider = OpenAIProvider(model=model_name)
        
        return VideoAnalyzer(provider=provider)
    
    def _create_analyzer(self, provider_name: str) -> VideoAnalyzer:
        """Providerì— ë”°ë¥¸ Analyzer ìƒì„± (í˜¸í™˜ì„±)"""
        providers = {
            "openai": OpenAIProvider,
            "claude": ClaudeProvider,
            "gemini": GeminiProvider
        }
        
        provider_class = providers.get(provider_name, OpenAIProvider)
        provider = provider_class()
        
        return VideoAnalyzer(provider=provider)
    
    def can_skip(self, context: PipelineContext) -> bool:
        """ìºì‹œ íˆíŠ¸ ì‹œ ìŠ¤í‚µ"""
        return context.stage_results.get("cache_hit", False)
    
    def execute(self, context: PipelineContext) -> PipelineContext:
        """AI ë¶„ì„ ì‹¤í–‰"""
        video = context.video_object
        
        if not video.scenes:
            self.logger.warning("ë¶„ì„í•  ì”¬ì´ ì—†ìŠµë‹ˆë‹¤")
            return context
        
        # ëª¨ë¸ í‘œì‹œëª…
        model_display = {
            "gemini-2.0-flash": "Google Gemini",
            "gpt-4o": "GPT-4o",
            "claude-sonnet-4-20250514": "Claude Sonnet 4"
        }.get(self.model_name, self.model_name)
        
        self.update_progress(0, f"ğŸ¤– {model_display} AI ë¶„ì„ ì‹œì‘...", context)
        
        # custom_promptê°€ ìˆìœ¼ë©´ analyzerì— ì „ë‹¬
        if context.custom_prompt:
            self.analyzer.custom_prompt = context.custom_prompt
            self.logger.info(f"ğŸ“ ë§ì¶¤í˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
        
        # AI ë¶„ì„ ì‹¤í–‰
        analysis_result = self.analyzer.analyze_video(video)
        
        # ì‚¬ìš©ëœ ì „ì²´ í”„ë¡¬í”„íŠ¸ ì €ì¥
        if hasattr(self.analyzer, 'last_full_prompt'):
            context.full_prompt_used = self.analyzer.last_full_prompt
        
        if analysis_result:
            self.update_progress(70, f"âœ… AI ë¶„ì„ ì„±ê³µ: {analysis_result.get('genre', 'Unknown')}", context)
            
            # Video ê°ì²´ì— ì €ì¥
            video.analysis_result = analysis_result
            context.analysis_result = analysis_result
            
            # ì „ì²´ í”„ë¡¬í”„íŠ¸ë„ Video ê°ì²´ì— ì €ì¥
            if hasattr(context, 'full_prompt_used'):
                video.full_prompt_used = context.full_prompt_used
            
            # DBì— ì €ì¥
            analysis_data = {
                'genre': analysis_result.get('genre', ''),
                'reasoning': analysis_result.get('reasoning', ''),
                'features': analysis_result.get('features', ''),
                'tags': analysis_result.get('tags', []),
                'expression_style': analysis_result.get('expression_style', ''),
                'mood_tone': analysis_result.get('mood_tone', ''),
                'target_audience': analysis_result.get('target_audience', ''),
                'analyzed_scenes': [os.path.basename(scene.frame_path) for scene in video.scenes[:10]],
                'token_usage': {},
                'model_used': analysis_result.get('model_used', f'{self.provider_name}:unknown')
            }
            
            self.db.save_analysis_result(context.video_id, analysis_data)
            
            self.update_progress(100, "âœ… AI ë¶„ì„ ì™„ë£Œ", context)
        else:
            self.update_progress(80, "âš ï¸ AI ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤", context)
        
        return context
