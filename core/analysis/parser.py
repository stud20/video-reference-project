# core/analysis/parser.py
"""AI ì‘ë‹µ íŒŒì‹± ëª¨ë“ˆ"""

import re
import json
import os
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from utils.logger import get_logger


@dataclass
class ParsedAnalysis:
    """íŒŒì‹±ëœ ë¶„ì„ ê²°ê³¼"""
    genre: str = "Unknown"
    reason: str = "ë¶„ì„ ë‚´ìš© ì—†ìŒ"
    features: str = "ë¶„ì„ ë‚´ìš© ì—†ìŒ"
    tags: List[str] = None
    format_type: str = "ì‹¤ì‚¬"
    mood: str = ""
    target_audience: str = ""
    raw_response: str = ""
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'genre': self.genre,
            'reasoning': self.reason,
            'features': self.features,
            'tags': self.tags,
            'expression_style': self.format_type,
            'mood_tone': self.mood,
            'target_audience': self.target_audience
        }


class ResponseParser:
    """AI ì‘ë‹µ íŒŒì„œ"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        
        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì„¤ì • ë¡œë“œ
        self._load_custom_settings()
        
        # íŒŒì‹± íŒ¨í„´ë“¤
        self.patterns = self._build_patterns()
    
    def _load_custom_settings(self):
        """ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì„¤ì • ë¡œë“œ"""
        settings_file = "config/prompt_settings.json"
        
        # ê¸°ë³¸ ë¶„ì„ í•­ëª©
        self.analysis_items = [
            {"label": "A1", "field": "genre"},
            {"label": "A2", "field": "reason"},
            {"label": "A3", "field": "features"},
            {"label": "A4", "field": "tags"},
            {"label": "A5", "field": "format_type"},
            {"label": "A6", "field": "mood"},
            {"label": "A7", "field": "target_audience"}
        ]
        
        if os.path.exists(settings_file):
            try:
                with open(settings_file, 'r', encoding='utf-8') as f:
                    settings = json.load(f)
                
                # ë¶„ì„ í•­ëª©ì´ ìˆìœ¼ë©´ ë§¤í•‘ ì—…ë°ì´íŠ¸
                if 'analysis_items' in settings:
                    custom_items = settings['analysis_items']
                    
                    # ë ˆì´ë¸”ê³¼ í•„ë“œ ë§¤í•‘ ì—…ë°ì´íŠ¸
                    for i, item in enumerate(custom_items[:7]):  # ìµœëŒ€ 7ê°œ í•­ëª©
                        if i < len(self.analysis_items):
                            self.analysis_items[i]["label"] = item.get("label", f"A{i+1}")
                            # ì œëª©ì—ì„œ í•„ë“œ íƒ€ì… ì¶”ì • (ì„ íƒì‚¬í•­)
                            title = item.get("title", "").lower()
                            if "ì¥ë¥´" in title:
                                self.analysis_items[i]["field"] = "genre"
                            elif "ì´ìœ " in title or "íŒë‹¨" in title:
                                self.analysis_items[i]["field"] = "reason"
                            elif "íŠ¹ì§•" in title or "íŠ¹ì´" in title:
                                self.analysis_items[i]["field"] = "features"
                            elif "íƒœê·¸" in title or "í‚¤ì›Œë“œ" in title:
                                self.analysis_items[i]["field"] = "tags"
                            elif "í‘œí˜„" in title or "í˜•ì‹" in title:
                                self.analysis_items[i]["field"] = "format_type"
                            elif "ë¶„ìœ„ê¸°" in title or "í†¤" in title:
                                self.analysis_items[i]["field"] = "mood"
                            elif "íƒ€ê²Ÿ" in title or "ê³ ê°" in title:
                                self.analysis_items[i]["field"] = "target_audience"
                
                self.logger.info("âœ… ì»¤ìŠ¤í…€ íŒŒì‹± ì„¤ì • ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                self.logger.error(f"ì»¤ìŠ¤í…€ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def _build_patterns(self) -> Dict[str, Dict[str, str]]:
        """ë™ì  íŒŒì‹± íŒ¨í„´ ìƒì„±"""
        labeled_patterns = {}
        
        # ì»¤ìŠ¤í…€ ë ˆì´ë¸” ê¸°ë°˜ íŒ¨í„´ ìƒì„±
        for i, item in enumerate(self.analysis_items):
            label = item["label"]
            field = item["field"]
            
            # ë‹¤ìŒ ë ˆì´ë¸”ê¹Œì§€ ë˜ëŠ” ëê¹Œì§€ ë§¤ì¹­
            if i < len(self.analysis_items) - 1:
                next_label = self.analysis_items[i + 1]["label"]
                pattern = rf'{label}[.\s]*[:ï¼š]?\s*(.+?)(?={next_label}|$)'
            else:
                pattern = rf'{label}[.\s]*[:ï¼š]?\s*(.+?)(?=$)'
            
            labeled_patterns[field] = pattern
        
        return {
            'labeled': labeled_patterns,
            'section': {
                'sections': r'(?:^|\n\n)(.+?)(?=\n\n|$)'
            }
        }
    
    def parse(self, response: str) -> Optional[ParsedAnalysis]:
        """AI ì‘ë‹µ íŒŒì‹±
        
        Args:
            response: AIì˜ ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            íŒŒì‹±ëœ ë¶„ì„ ê²°ê³¼ ë˜ëŠ” None
        """
        if not response or len(response) < 100:
            self.logger.error(f"ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŒ: {len(response) if response else 0}ì")
            return None
        
        # íŒŒì‹± ì „ì— ìµœì‹  ì„¤ì • ë‹¤ì‹œ ë¡œë“œ
        self._load_custom_settings()
        self.patterns = self._build_patterns()
        
        self.logger.info("ğŸ“ ì‘ë‹µ íŒŒì‹± ì‹œì‘...")
        self.logger.debug(f"ğŸ“Š ë¡œë“œëœ ë¶„ì„ í•­ëª© ê°œìˆ˜: {len(self.analysis_items)}")
        self.logger.debug(f"ğŸ“Š ì²« ë²ˆì§¸ í•­ëª©: {self.analysis_items[0] if self.analysis_items else 'None'}")
        self.logger.debug(f"ğŸ“Š ì‘ë‹µ ê¸¸ì´: {len(response)}ì")
        
        # ì—¬ëŸ¬ íŒŒì‹± ì „ëµ ì‹œë„
        result = None
        
        # 1. ë ˆì´ë¸” ê¸°ë°˜ íŒŒì‹± ì‹œë„ (ì»¤ìŠ¤í…€ ë ˆì´ë¸” ì‚¬ìš©)
        result = self._parse_labeled_format(response)
        if result and self._validate_result(result):
            self.logger.info("âœ… ë ˆì´ë¸” í˜•ì‹ íŒŒì‹± ì„±ê³µ")
            return result
        
        # 2. ì„¹ì…˜ ê¸°ë°˜ íŒŒì‹± ì‹œë„ (ë¹ˆ ì¤„ë¡œ êµ¬ë¶„)
        result = self._parse_section_format(response)
        if result and self._validate_result(result):
            self.logger.info("âœ… ì„¹ì…˜ í˜•ì‹ íŒŒì‹± ì„±ê³µ")
            return result
        
        # 3. ììœ  í˜•ì‹ íŒŒì‹± ì‹œë„ (í‚¤ì›Œë“œ ê¸°ë°˜)
        result = self._parse_free_format(response)
        if result and self._validate_result(result):
            self.logger.info("âœ… ììœ  í˜•ì‹ íŒŒì‹± ì„±ê³µ")
            return result
        
        # 4. ìµœì†Œí•œì˜ ì •ë³´ë¼ë„ ì¶”ì¶œ
        self.logger.warning("âš ï¸ ì •êµí•œ íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ íŒŒì‹± ì‹œë„")
        return self._parse_minimal(response)
    
    def _parse_labeled_format(self, response: str) -> Optional[ParsedAnalysis]:
        """ë ˆì´ë¸” í˜•ì‹ íŒŒì‹± (ì»¤ìŠ¤í…€ ë ˆì´ë¸” ì§€ì›)"""
        try:
            result = ParsedAnalysis(raw_response=response)
            
            # ê° í•„ë“œ ì¶”ì¶œ
            for field, pattern in self.patterns['labeled'].items():
                match = re.search(pattern, response, re.MULTILINE | re.DOTALL)
                if match:
                    value = match.group(1).strip()
                    
                    if field == 'tags':
                        # íƒœê·¸ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        result.tags = self._parse_tags(value)
                    else:
                        setattr(result, field, self._clean_text(value))
            
            return result
            
        except Exception as e:
            self.logger.error(f"ë ˆì´ë¸” í˜•ì‹ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _parse_section_format(self, response: str) -> Optional[ParsedAnalysis]:
        """ì„¹ì…˜ í˜•ì‹ íŒŒì‹± (ë¹ˆ ì¤„ë¡œ êµ¬ë¶„)"""
        try:
            # ë¹ˆ ì¤„ë¡œ ì„¹ì…˜ ë¶„ë¦¬
            sections = []
            current_section = []
            
            for line in response.strip().split('\n'):
                if line.strip():
                    current_section.append(line)
                else:
                    if current_section:
                        sections.append('\n'.join(current_section))
                        current_section = []
            
            if current_section:
                sections.append('\n'.join(current_section))
            
            if len(sections) < 4:  # ìµœì†Œ 4ê°œ ì„¹ì…˜ í•„ìš”
                return None
            
            # ì„¹ì…˜ì„ ìˆœì„œëŒ€ë¡œ ë§¤í•‘
            result = ParsedAnalysis(raw_response=response)
            
            # ì»¤ìŠ¤í…€ í•­ëª© ìˆœì„œì— ë”°ë¼ ë§¤í•‘
            for i, section in enumerate(sections):
                if i < len(self.analysis_items):
                    field = self.analysis_items[i]["field"]
                    
                    if field == "tags":
                        result.tags = self._parse_tags(section)
                    elif field in ["genre", "format_type"]:
                        setattr(result, field, self._extract_first_line(section))
                    else:
                        setattr(result, field, self._clean_text(section))
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì„¹ì…˜ í˜•ì‹ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _parse_free_format(self, response: str) -> Optional[ParsedAnalysis]:
        """ììœ  í˜•ì‹ íŒŒì‹± (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            result = ParsedAnalysis(raw_response=response)
            
            # ì¥ë¥´ ì°¾ê¸°
            genre_keywords = ["ì¥ë¥´", "ë¶„ë¥˜", "ì¹´í…Œê³ ë¦¬", "íƒ€ì…", "ìœ í˜•"]
            for keyword in genre_keywords:
                pattern = rf'{keyword}[:\s]*([^\n]+)'
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    result.genre = self._extract_first_line(match.group(1))
                    break
            
            # íƒœê·¸ ì°¾ê¸°
            tag_keywords = ["íƒœê·¸", "í‚¤ì›Œë“œ", "ê´€ë ¨ì–´", "ì—°ê´€ì–´"]
            for keyword in tag_keywords:
                pattern = rf'{keyword}[:\s]*([^\n]+(?:\n[^\n]+)*)'
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    result.tags = self._parse_tags(match.group(1))
                    break
            
            # ë‚˜ë¨¸ì§€ í•„ë“œëŠ” í…ìŠ¤íŠ¸ì˜ ìˆœì„œì™€ ê¸¸ì´ë¡œ ì¶”ì •
            lines = [line.strip() for line in response.split('\n') if line.strip()]
            
            # ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì´ìœ ì™€ íŠ¹ì§•ìœ¼ë¡œ ë¶„ë¥˜
            long_texts = [line for line in lines if len(line) > 100]
            if len(long_texts) >= 2:
                result.reason = long_texts[0]
                result.features = long_texts[1]
            elif len(long_texts) == 1:
                result.reason = long_texts[0]
                result.features = "ë¶„ì„ ë‚´ìš© ì—†ìŒ"
            
            return result
            
        except Exception as e:
            self.logger.error(f"ììœ  í˜•ì‹ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _parse_minimal(self, response: str) -> ParsedAnalysis:
        """ìµœì†Œí•œì˜ ì •ë³´ ì¶”ì¶œ"""
        result = ParsedAnalysis(raw_response=response)
        
        # ì²« ì¤„ì„ ì¥ë¥´ë¡œ ê°€ì •
        lines = [line.strip() for line in response.split('\n') if line.strip()]
        if lines:
            result.genre = self._extract_first_line(lines[0])
        
        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì´ìœ ë¡œ ì‚¬ìš©
        result.reason = response[:500] + "..." if len(response) > 500 else response
        
        # íƒœê·¸ ì¶”ì¶œ ì‹œë„
        result.tags = self._extract_potential_tags(response)
        
        return result
    
    def _parse_tags(self, text: str) -> List[str]:
        """íƒœê·¸ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        # ì—¬ëŸ¬ êµ¬ë¶„ì ì²˜ë¦¬
        delimiters = [',', '/', '#', 'Â·', '|', '\n']
        
        # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ êµ¬ë¶„ì ì°¾ê¸°
        delimiter_counts = {d: text.count(d) for d in delimiters}
        main_delimiter = max(delimiter_counts, key=delimiter_counts.get)
        
        if delimiter_counts[main_delimiter] == 0:
            # êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
            tags = text.split()
        else:
            tags = text.split(main_delimiter)
        
        # ì •ë¦¬
        cleaned_tags = []
        for tag in tags:
            tag = tag.strip()
            # íŠ¹ìˆ˜ë¬¸ì ì œê±°
            tag = re.sub(r'^[#\-\*\Â·\s]+', '', tag)
            tag = re.sub(r'[#\-\*\Â·\s]+$', '', tag)
            
            if tag and len(tag) > 1 and len(tag) < 50:
                cleaned_tags.append(tag)
        
        return cleaned_tags[:20]  # ìµœëŒ€ 20ê°œ
    
    def _extract_potential_tags(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì ì¬ì ì¸ íƒœê·¸ ì¶”ì¶œ"""
        # í•œê¸€ ë‹¨ì–´ ì¶”ì¶œ (2-10ì)
        korean_words = re.findall(r'[ê°€-í£]{2,10}', text)
        
        # ë¹ˆë„ìˆ˜ ê³„ì‚°
        word_freq = {}
        for word in korean_words:
            if word not in ['ì˜ìƒ', 'ë¶„ì„', 'ì´ë¯¸ì§€', 'ë‚´ìš©', 'ê²½ìš°']:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        
        return [word for word, freq in sorted_words[:10]]
    
    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        # ì»¤ìŠ¤í…€ ë ˆì´ë¸” íŒ¨í„´ ì œê±°
        for item in self.analysis_items:
            label = item["label"]
            text = re.sub(rf'^{label}[.\s]*[:ï¼š]?\s*', '', text.strip())
        
        # ì•ë’¤ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = re.sub(r'^[-\*\Â·\s]+', '', text)
        text = re.sub(r'[-\*\Â·\s]+$', '', text)
        
        return text.strip()
    
    def _extract_first_line(self, text: str) -> str:
        """ì²« ì¤„ ë˜ëŠ” ì§§ì€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        text = self._clean_text(text)
        
        # ì²« ì¤„ë§Œ ì¶”ì¶œ (ì¥ë¥´ë‚˜ í˜•ì‹ ê°™ì€ ì§§ì€ ë‹µë³€ìš©)
        first_line = text.split('\n')[0].strip()
        
        # ë„ˆë¬´ ê¸¸ë©´ ì²« 50ìë§Œ
        return first_line[:50] if len(first_line) > 50 else first_line
    
    def _validate_result(self, result: ParsedAnalysis) -> bool:
        """íŒŒì‹± ê²°ê³¼ ìœ íš¨ì„± ê²€ì‚¬"""
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if result.genre == "Unknown" or not result.genre:
            self.logger.warning(f"âš ï¸ ì¥ë¥´ ì •ë³´ ë¶€ì¡±: '{result.genre}'")
            return False
        
        if result.reason == "ë¶„ì„ ë‚´ìš© ì—†ìŒ" or len(result.reason) < 20:
            self.logger.warning(f"âš ï¸ ì´ìœ  ì„¤ëª… ë¶€ì¡±: {len(result.reason)}ì")
            return False
        
        self.logger.info(f"âœ… íŒŒì‹± ê²°ê³¼ ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼: ì¥ë¥´={result.genre}, ì´ìœ ={len(result.reason)}ì")
        return True
