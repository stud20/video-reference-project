# core/analysis/parser.py
"""AI ì‘ë‹µ íŒŒì‹± ëª¨ë“ˆ - ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ë²„ì „"""

import re
import json
import os
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from utils.logger import get_logger


@dataclass
class ParsedAnalysis:
    """íŒŒì‹±ëœ ë¶„ì„ ê²°ê³¼"""
    genre: str = "Unknown"
    reason: str = "ë¶„ì„ ë‚´ìš© ì—†ìŒ"
    features: str = "ë¶„ì„ ë‚´ìš© ì—†ìŒ"
    tags: List[str] = None
    format_type: str = "ì‹¤ì‚¬"
    mood: str = ""
    target_audience: str = ""
    raw_response: str = ""
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'genre': self.genre,
            'reasoning': self.reason,
            'features': self.features,
            'tags': self.tags,
            'expression_style': self.format_type,
            'mood_tone': self.mood,
            'target_audience': self.target_audience
        }


class ResponseParser:
    """AI ì‘ë‹µ íŒŒì„œ"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
    
    def parse(self, response: str) -> Optional[ParsedAnalysis]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        if not response or len(response) < 100:
            self.logger.error(f"ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŒ: {len(response) if response else 0}ì")
            return None
        
        self.logger.info("ğŸ“ ì‘ë‹µ íŒŒì‹± ì‹œì‘...")
        
        try:
            result = ParsedAnalysis(raw_response=response)
            
            # A1-A7 íŒ¨í„´ìœ¼ë¡œ ì§ì ‘ íŒŒì‹±
            patterns = {
                'genre': r'A1[.\s]*[:ï¼š]?\s*(.+?)(?=\n\s*A2|$)',
                'reason': r'A2[.\s]*[:ï¼š]?\s*(.+?)(?=\n\s*A3|$)',
                'features': r'A3[.\s]*[:ï¼š]?\s*(.+?)(?=\n\s*A4|$)',
                'tags': r'A4[.\s]*[:ï¼š]?\s*(.+?)(?=\n\s*A5|$)',
                'format_type': r'A5[.\s]*[:ï¼š]?\s*(.+?)(?=\n\s*A6|$)',
                'mood': r'A6[.\s]*[:ï¼š]?\s*(.+?)(?=\n\s*A7|$)',
                'target_audience': r'A7[.\s]*[:ï¼š]?\s*(.+?)$'
            }
            
            # ê° íŒ¨í„´ ë§¤ì¹­
            for field, pattern in patterns.items():
                match = re.search(pattern, response, re.MULTILINE | re.DOTALL)
                if match:
                    value = match.group(1).strip()
                    
                    if field == 'tags':
                        # íƒœê·¸ëŠ” ì‰¼í‘œë¡œ ë¶„ë¦¬
                        tag_list = [tag.strip() for tag in value.split(',') if tag.strip()]
                        result.tags = tag_list[:20]  # ìµœëŒ€ 20ê°œ
                        self.logger.debug(f"âœ… íƒœê·¸ {len(result.tags)}ê°œ íŒŒì‹±ë¨")
                    else:
                        setattr(result, field, value)
                        self.logger.debug(f"âœ… {field} íŒŒì‹±ë¨: {value[:50]}...")
                else:
                    self.logger.warning(f"âš ï¸ {field} ë§¤ì¹­ ì‹¤íŒ¨")
            
            # ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦
            if self._validate_result(result):
                self.logger.info("âœ… íŒŒì‹± ì„±ê³µ")
                return result
            else:
                # ì„¹ì…˜ ê¸°ë°˜ íŒŒì‹± ì‹œë„
                self.logger.info("ğŸ”„ ì„¹ì…˜ ê¸°ë°˜ íŒŒì‹± ì‹œë„")
                return self._parse_section_format(response)
                
        except Exception as e:
            self.logger.error(f"íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return self._parse_minimal(response)
    
    def _parse_section_format(self, response: str) -> Optional[ParsedAnalysis]:
        """ì„¹ì…˜ ê¸°ë°˜ íŒŒì‹± (ë¹ˆ ì¤„ë¡œ êµ¬ë¶„)"""
        try:
            sections = []
            current_section = []
            
            for line in response.strip().split('\n'):
                if line.strip():
                    current_section.append(line)
                else:
                    if current_section:
                        sections.append('\n'.join(current_section))
                        current_section = []
            
            if current_section:
                sections.append('\n'.join(current_section))
            
            if len(sections) < 4:
                return None
            
            result = ParsedAnalysis(raw_response=response)
            
            # ì„¹ì…˜ì„ ìˆœì„œëŒ€ë¡œ ë§¤í•‘
            fields = ['genre', 'reason', 'features', 'tags', 'format_type', 'mood', 'target_audience']
            
            for i, section in enumerate(sections):
                if i < len(fields):
                    field = fields[i]
                    clean_section = self._clean_section(section)
                    
                    if field == 'tags':
                        tag_list = [tag.strip() for tag in clean_section.replace(',', ' ').split() if tag.strip()]
                        result.tags = tag_list[:20]
                    elif field in ['genre', 'format_type']:
                        # ì²« ì¤„ë§Œ ì¶”ì¶œ
                        result.__dict__[field] = clean_section.split('\n')[0].strip()
                    else:
                        result.__dict__[field] = clean_section
            
            return result if self._validate_result(result) else None
            
        except Exception as e:
            self.logger.error(f"ì„¹ì…˜ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _parse_minimal(self, response: str) -> ParsedAnalysis:
        """ìµœì†Œí•œì˜ ì •ë³´ ì¶”ì¶œ"""
        result = ParsedAnalysis(raw_response=response)
        
        # ì²« ì¤„ì„ ì¥ë¥´ë¡œ ì¶”ì •
        lines = [line.strip() for line in response.split('\n') if line.strip()]
        if lines:
            result.genre = self._extract_genre_from_line(lines[0])
        
        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì´ìœ ë¡œ ì‚¬ìš©
        result.reason = response[:500] + "..." if len(response) > 500 else response
        
        # ê°„ë‹¨í•œ íƒœê·¸ ì¶”ì¶œ
        result.tags = self._extract_simple_tags(response)
        
        return result
    
    def _clean_section(self, section: str) -> str:
        """ì„¹ì…˜ í…ìŠ¤íŠ¸ ì •ë¦¬"""
        # A1., A2. ë“±ì˜ ë ˆì´ë¸” ì œê±°
        section = re.sub(r'^A\d+[.\s]*[:ï¼š]?\s*', '', section.strip())
        return section.strip()
    
    def _extract_genre_from_line(self, line: str) -> str:
        """ì¤„ì—ì„œ ì¥ë¥´ ì¶”ì¶œ"""
        line = self._clean_section(line)
        # ì²« 50ìë§Œ ë°˜í™˜
        return line[:50] if len(line) > 50 else line
    
    def _extract_simple_tags(self, text: str) -> List[str]:
        """ê°„ë‹¨í•œ íƒœê·¸ ì¶”ì¶œ"""
        # í•œê¸€ ë‹¨ì–´ë§Œ ì¶”ì¶œ (2-10ì)
        korean_words = re.findall(r'[ê°€-í£]{2,10}', text)
        
        # ë¹ˆë„ìˆ˜ ê³„ì‚° ë° ì •ë¦¬
        word_freq = {}
        exclude_words = {'ì˜ìƒ', 'ë¶„ì„', 'ì´ë¯¸ì§€', 'ë‚´ìš©', 'ê²½ìš°', 'ìˆìŠµë‹ˆë‹¤', 'ìˆìœ¼ë©°', 'í™œìš©í•˜ì—¬', 'íŠ¹ì§•ì„'}
        
        for word in korean_words:
            if word not in exclude_words:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¹ˆë„ìˆœ ì •ë ¬í•˜ì—¬ ìƒìœ„ 10ê°œ ë°˜í™˜
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in sorted_words[:10]]
    
    def _validate_result(self, result: ParsedAnalysis) -> bool:
        """íŒŒì‹± ê²°ê³¼ ìœ íš¨ì„± ê²€ì‚¬"""
        if result.genre == "Unknown" or not result.genre:
            self.logger.warning("âš ï¸ ì¥ë¥´ ì •ë³´ ë¶€ì¡±")
            return False
        
        if result.reason == "ë¶„ì„ ë‚´ìš© ì—†ìŒ" or len(result.reason) < 20:
            self.logger.warning("âš ï¸ ì´ìœ  ì„¤ëª… ë¶€ì¡±")
            return False
        
        self.logger.info(f"âœ… íŒŒì‹± ê²€ì¦ í†µê³¼: ì¥ë¥´={result.genre}, ì´ìœ ={len(result.reason)}ì")
        return True
